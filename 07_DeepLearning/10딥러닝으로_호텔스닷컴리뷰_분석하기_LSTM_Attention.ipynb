{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6282eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 13:08:07.609215: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-14 13:08:07.619426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-14 13:08:07.629451: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-14 13:08:07.632657: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-14 13:08:07.640896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import koreanize_matplotlib\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b1d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/data4mdai/main/hotelscom_review_train.csv\")\n",
    "test_data = pd.read_csv(\"../06machine_learning/data/hotelscom_review_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f21027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>isgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>사람이 너무 많고 작은 수영장과 조식 수용한계로 모두 포기하고 옆의 아이파크몰에서 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>방도크고 깨끗하여 아주 좋았어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>매년여름휴가철마다 찾는곳이예요 너무 좋아요 점점 더 좋아지는듯 직원분들도 너무 친절...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>여수에서는 제일 유명한 호텔이래요 호텔 stay 가 필요하다면 소노캄 여수도 괜찮은...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가격대비 훌륭하지만 아무래도 오래된 느낌이 많이 드네요겉이불은 세탁하니까 깨끗히나 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  isgood\n",
       "0  사람이 너무 많고 작은 수영장과 조식 수용한계로 모두 포기하고 옆의 아이파크몰에서 ...       0\n",
       "1                                  방도크고 깨끗하여 아주 좋았어요       1\n",
       "2  매년여름휴가철마다 찾는곳이예요 너무 좋아요 점점 더 좋아지는듯 직원분들도 너무 친절...       1\n",
       "3  여수에서는 제일 유명한 호텔이래요 호텔 stay 가 필요하다면 소노캄 여수도 괜찮은...       1\n",
       "4  가격대비 훌륭하지만 아무래도 오래된 느낌이 많이 드네요겉이불은 세탁하니까 깨끗히나 ...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe66d22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53964 entries, 0 to 53963\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   description  53964 non-null  object\n",
      " 1   isgood       53964 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 843.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206edcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35977 entries, 0 to 35976\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   description  35977 non-null  object\n",
      " 1   isgood       35977 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 562.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d9f96",
   "metadata": {},
   "source": [
    "# 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c0e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = train_data['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bbc8211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사람',\n",
       " '이',\n",
       " '너무',\n",
       " '많',\n",
       " '고',\n",
       " '작',\n",
       " '은',\n",
       " '수영장',\n",
       " '과',\n",
       " '조식',\n",
       " '수용',\n",
       " '한계',\n",
       " '로',\n",
       " '모두',\n",
       " '포기',\n",
       " '하',\n",
       " '고',\n",
       " '옆',\n",
       " '의',\n",
       " '아이파크몰',\n",
       " '에서',\n",
       " '그냥',\n",
       " '식사',\n",
       " '함']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab = Mecab()\n",
    "mecab.morphs(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c644ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6f25d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.89 s, sys: 39.6 ms, total: 4.93 s\n",
      "Wall time: 5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 전체 문장을 토큰화 후 tokenized_docs에 저장\n",
    "tokenized_docs = docs.apply(mecab.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8f1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(tokenized_docs, \"./model/hotels_tokenized_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "492f3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_docs = joblib.load(\"./model/hotels_tokenized_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f5043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d393ef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30149\n"
     ]
    }
   ],
   "source": [
    "# 단어 인덱스 생성\n",
    "token = Tokenizer(lower=False)\n",
    "token.fit_on_texts(tokenized_docs)\n",
    "print(len(token.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eede2088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 1, 30, 81, 2, 146, 10, 168, 56, 51, 3466, 3762, 47, 167, 1858, 3, 2, 231, 32, 3068, 27, 205, 221, 71]\n"
     ]
    }
   ],
   "source": [
    "# 문장 백터화 \n",
    "X = token.texts_to_sequences(tokenized_docs)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed04063a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "53959    1\n",
       "53960    1\n",
       "53961    1\n",
       "53962    1\n",
       "53963    1\n",
       "Name: isgood, Length: 53964, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_data['isgood']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "850dab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 문장의 길이(패딩에 사용):  738\n"
     ]
    }
   ],
   "source": [
    "# 가장 긴 문장의 길이 구하기\n",
    "max_len = max(len(i) for i in X)\n",
    "print(\"가장 긴 문장의 길이(패딩에 사용): \", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05eb7894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 200    1   30   81    2  146   10  168   56   51 3466 3762   47  167\n",
      " 1858    3    2  231   32 3068   27  205  221   71    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 패딩\n",
    "X_padded = pad_sequences(X, maxlen=max_len, padding='post')\n",
    "print(X_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "271b94a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홀드아웃\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e5fde6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_padded, y, test_size=0.3 ,stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9bde98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30150\n"
     ]
    }
   ],
   "source": [
    "# 임베딩에 입력될 단어 수\n",
    "word_size = len(token.word_index) + 1 \n",
    "print(word_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c942a",
   "metadata": {},
   "source": [
    "# 양방향 RNN 네트워크를 이용해 텍스트 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81baa261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85a4affc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,929,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m1,929,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_7 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m20,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,001,665</span> (7.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,001,665\u001b[0m (7.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,001,665</span> (7.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,001,665\u001b[0m (7.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "birnn = Sequential()\n",
    "birnn.add(Embedding(input_dim=word_size, output_dim=64))\n",
    "birnn.add(Bidirectional(SimpleRNN(128, return_sequences=True, activation='tanh')))\n",
    "birnn.add(Dropout(0.5))\n",
    "birnn.add(SimpleRNN(64, activation='tanh'))\n",
    "birnn.add(Dropout(0.5))\n",
    "birnn.add(Dense(32, activation='relu'))\n",
    "birnn.add(Dense(1, activation='sigmoid'))\n",
    "# 모델 요약\n",
    "birnn.build(input_shape=(None, max_len))  # 입력 형태 지정\n",
    "birnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9573db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "birnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelpath = \"./model/hotels_review_birnn.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath=modelpath, save_best_only=True)\n",
    "earlystop = EarlyStopping(patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95d88965",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 505ms/step - accuracy: 0.7803 - loss: 0.5295 - val_accuracy: 0.7812 - val_loss: 0.5264\n",
      "Epoch 2/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 530ms/step - accuracy: 0.7795 - loss: 0.5294 - val_accuracy: 0.7812 - val_loss: 0.5267\n",
      "Epoch 3/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 480ms/step - accuracy: 0.7839 - loss: 0.5238 - val_accuracy: 0.7812 - val_loss: 0.5266\n",
      "Epoch 4/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 504ms/step - accuracy: 0.7828 - loss: 0.5253 - val_accuracy: 0.7812 - val_loss: 0.5298\n",
      "Epoch 5/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 470ms/step - accuracy: 0.7804 - loss: 0.5288 - val_accuracy: 0.7812 - val_loss: 0.5270\n",
      "Epoch 6/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 462ms/step - accuracy: 0.7839 - loss: 0.5235 - val_accuracy: 0.7812 - val_loss: 0.5266\n",
      "Epoch 7/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 460ms/step - accuracy: 0.7827 - loss: 0.5247 - val_accuracy: 0.7812 - val_loss: 0.5276\n",
      "Epoch 8/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 501ms/step - accuracy: 0.7804 - loss: 0.5281 - val_accuracy: 0.7812 - val_loss: 0.5282\n",
      "Epoch 9/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 512ms/step - accuracy: 0.7812 - loss: 0.5271 - val_accuracy: 0.7812 - val_loss: 0.5278\n",
      "Epoch 10/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 477ms/step - accuracy: 0.7788 - loss: 0.5296 - val_accuracy: 0.7812 - val_loss: 0.5291\n",
      "Epoch 11/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 489ms/step - accuracy: 0.7814 - loss: 0.5265 - val_accuracy: 0.7812 - val_loss: 0.5268\n",
      "Epoch 12/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 472ms/step - accuracy: 0.7792 - loss: 0.5292 - val_accuracy: 0.7812 - val_loss: 0.5259\n",
      "Epoch 13/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 458ms/step - accuracy: 0.7859 - loss: 0.5200 - val_accuracy: 0.7812 - val_loss: 0.5271\n",
      "Epoch 14/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 463ms/step - accuracy: 0.7810 - loss: 0.5276 - val_accuracy: 0.7812 - val_loss: 0.5297\n",
      "Epoch 15/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 527ms/step - accuracy: 0.7758 - loss: 0.5335 - val_accuracy: 0.7812 - val_loss: 0.5281\n",
      "Epoch 16/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 475ms/step - accuracy: 0.7837 - loss: 0.5232 - val_accuracy: 0.7812 - val_loss: 0.5296\n",
      "Epoch 17/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 496ms/step - accuracy: 0.7784 - loss: 0.5305 - val_accuracy: 0.7812 - val_loss: 0.5262\n",
      "Epoch 18/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 481ms/step - accuracy: 0.7823 - loss: 0.5252 - val_accuracy: 0.7812 - val_loss: 0.5310\n",
      "Epoch 19/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 493ms/step - accuracy: 0.7794 - loss: 0.5290 - val_accuracy: 0.7812 - val_loss: 0.5271\n",
      "Epoch 20/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 489ms/step - accuracy: 0.7792 - loss: 0.5290 - val_accuracy: 0.7812 - val_loss: 0.5288\n",
      "Epoch 21/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 506ms/step - accuracy: 0.7844 - loss: 0.5223 - val_accuracy: 0.7812 - val_loss: 0.5283\n",
      "Epoch 22/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 524ms/step - accuracy: 0.7831 - loss: 0.5238 - val_accuracy: 0.7812 - val_loss: 0.5273\n",
      "Epoch 23/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 516ms/step - accuracy: 0.7815 - loss: 0.5257 - val_accuracy: 0.7812 - val_loss: 0.5272\n",
      "Epoch 24/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 497ms/step - accuracy: 0.7791 - loss: 0.5281 - val_accuracy: 0.7812 - val_loss: 0.5279\n",
      "Epoch 25/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 484ms/step - accuracy: 0.7778 - loss: 0.5310 - val_accuracy: 0.7812 - val_loss: 0.5276\n",
      "Epoch 26/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 491ms/step - accuracy: 0.7828 - loss: 0.5241 - val_accuracy: 0.7812 - val_loss: 0.5268\n",
      "Epoch 27/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 496ms/step - accuracy: 0.7812 - loss: 0.5260 - val_accuracy: 0.7812 - val_loss: 0.5282\n",
      "Epoch 28/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 542ms/step - accuracy: 0.7831 - loss: 0.5238 - val_accuracy: 0.7812 - val_loss: 0.5285\n",
      "Epoch 29/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 508ms/step - accuracy: 0.7796 - loss: 0.5284 - val_accuracy: 0.7812 - val_loss: 0.5280\n",
      "Epoch 30/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 507ms/step - accuracy: 0.7807 - loss: 0.5273 - val_accuracy: 0.7812 - val_loss: 0.5264\n",
      "Epoch 31/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 490ms/step - accuracy: 0.7822 - loss: 0.5256 - val_accuracy: 0.7812 - val_loss: 0.5278\n",
      "Epoch 32/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 480ms/step - accuracy: 0.7812 - loss: 0.5262 - val_accuracy: 0.7812 - val_loss: 0.5262\n",
      "Epoch 33/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 454ms/step - accuracy: 0.7835 - loss: 0.5230 - val_accuracy: 0.7812 - val_loss: 0.5262\n",
      "Epoch 34/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 458ms/step - accuracy: 0.7795 - loss: 0.5290 - val_accuracy: 0.7812 - val_loss: 0.5262\n",
      "Epoch 35/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 537ms/step - accuracy: 0.7771 - loss: 0.5315 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 36/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 493ms/step - accuracy: 0.7785 - loss: 0.5301 - val_accuracy: 0.7812 - val_loss: 0.5259\n",
      "Epoch 37/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 518ms/step - accuracy: 0.7799 - loss: 0.5277 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 38/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 471ms/step - accuracy: 0.7823 - loss: 0.5247 - val_accuracy: 0.7812 - val_loss: 0.5270\n",
      "Epoch 39/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 462ms/step - accuracy: 0.7792 - loss: 0.5287 - val_accuracy: 0.7812 - val_loss: 0.5280\n",
      "Epoch 40/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 460ms/step - accuracy: 0.7798 - loss: 0.5279 - val_accuracy: 0.7812 - val_loss: 0.5266\n",
      "Epoch 41/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 524ms/step - accuracy: 0.7801 - loss: 0.5274 - val_accuracy: 0.7812 - val_loss: 0.5269\n",
      "Epoch 42/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 531ms/step - accuracy: 0.7791 - loss: 0.5289 - val_accuracy: 0.7812 - val_loss: 0.5269\n",
      "Epoch 43/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 498ms/step - accuracy: 0.7776 - loss: 0.5309 - val_accuracy: 0.7812 - val_loss: 0.5260\n",
      "Epoch 44/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 484ms/step - accuracy: 0.7813 - loss: 0.5256 - val_accuracy: 0.7812 - val_loss: 0.5263\n",
      "Epoch 45/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 486ms/step - accuracy: 0.7819 - loss: 0.5250 - val_accuracy: 0.7812 - val_loss: 0.5261\n",
      "Epoch 46/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 479ms/step - accuracy: 0.7815 - loss: 0.5258 - val_accuracy: 0.7812 - val_loss: 0.5263\n",
      "Epoch 47/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 540ms/step - accuracy: 0.7843 - loss: 0.5222 - val_accuracy: 0.7812 - val_loss: 0.5256\n",
      "Epoch 48/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 541ms/step - accuracy: 0.7810 - loss: 0.5266 - val_accuracy: 0.7812 - val_loss: 0.5267\n",
      "Epoch 49/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 498ms/step - accuracy: 0.7840 - loss: 0.5224 - val_accuracy: 0.7812 - val_loss: 0.5286\n",
      "Epoch 50/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 498ms/step - accuracy: 0.7816 - loss: 0.5257 - val_accuracy: 0.7812 - val_loss: 0.5267\n",
      "Epoch 51/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 478ms/step - accuracy: 0.7800 - loss: 0.5276 - val_accuracy: 0.7812 - val_loss: 0.5257\n",
      "Epoch 52/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 475ms/step - accuracy: 0.7776 - loss: 0.5305 - val_accuracy: 0.7812 - val_loss: 0.5264\n",
      "Epoch 53/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 478ms/step - accuracy: 0.7820 - loss: 0.5247 - val_accuracy: 0.7812 - val_loss: 0.5261\n",
      "Epoch 54/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 504ms/step - accuracy: 0.7808 - loss: 0.5265 - val_accuracy: 0.7812 - val_loss: 0.5260\n",
      "Epoch 55/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 503ms/step - accuracy: 0.7814 - loss: 0.5261 - val_accuracy: 0.7812 - val_loss: 0.5261\n",
      "Epoch 56/1000\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 496ms/step - accuracy: 0.7829 - loss: 0.5236 - val_accuracy: 0.7812 - val_loss: 0.5258\n",
      "Epoch 57/1000\n",
      "\u001b[1m61/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 441ms/step - accuracy: 0.7784 - loss: 0.5295"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m birnn_history \u001b[38;5;241m=\u001b[39m \u001b[43mbirnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearlystop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "birnn_history = birnn.fit(X_train, y_train, epochs=1000, batch_size=512,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d44d7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_plot(x):\n",
    "    # 검증셋과 학습셋의 오차를 저장합니다.\n",
    "    y_vloss = x.history['val_loss']\n",
    "    y_loss = x.history['loss']\n",
    "\n",
    "    # 그래프로 표현해 봅니다.\n",
    "    x_len = np.arange(len(y_loss))\n",
    "    plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "    plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "    # 그래프에 그리드를 주고 레이블을 표시해 보겠습니다.\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "160b1fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_plot(birnn_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff2913",
   "metadata": {},
   "source": [
    "# LSTM과 CNN 조합 모델로 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa2d66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, Activation, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Activation, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc05730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726319354.370901     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726319354.381197     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726319354.381234     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726319354.383858     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726319354.384325     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726319354.384338     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726319354.521709     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726319354.521776     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-14 13:09:14.521786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1726319354.521814     243 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-14 13:09:14.521832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3600 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,929,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">734</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">179</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">328,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m1,929,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m734\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m183\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m179\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m82,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │       \u001b[38;5;34m788,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m328,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,179,777</span> (12.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,179,777\u001b[0m (12.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,179,777</span> (12.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,179,777\u001b[0m (12.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델의 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_size, output_dim=64))  # 임베딩 벡터의 차원을 64로 증가\n",
    "model.add(Dropout(0.5))  # Dropout 층 추가\n",
    "model.add(Conv1D(128, 5, padding='valid', activation='relu', strides=1))  # Conv1D 층 추가\n",
    "model.add(MaxPooling1D(pool_size=4))  # MaxPooling 층 추가\n",
    "model.add(Conv1D(128, 5, padding='valid', activation='relu', strides=1))  # 추가적인 Conv1D 층\n",
    "model.add(MaxPooling1D(pool_size=4))  # MaxPooling 층 추가\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True, activation='tanh')))  # 양방향 LSTM 층 추가\n",
    "model.add(Dropout(0.5))  # Dropout 층 추가\n",
    "model.add(LSTM(128, activation='tanh'))  # 추가적인 LSTM 층\n",
    "model.add(Dropout(0.5))  # Dropout 층 추가\n",
    "model.add(Dense(64, activation='relu'))  # Dense 층 추가\n",
    "model.add(Dense(32, activation='relu'))  # 추가적인 Dense 층\n",
    "model.add(Dense(1, activation='sigmoid'))  # 출력층\n",
    "# 모델 요약\n",
    "model.build(input_shape=(None, max_len))  # 입력 형태 지정\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5ee19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelpath = \"./model/hotels_review_LSTM_CNN.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath=modelpath, save_best_only=True)\n",
    "earlystop = EarlyStopping(patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb1d2984",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1726319753.756806     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.769036     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.780441     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.792057     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.803417     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.815754     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.828024     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.838699     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.852320     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.865392     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.878291     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.891880     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.905766     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.919345     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.933558     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.947141     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.963019     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.972401     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.975820     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.977968     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.980301     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.982939     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.985535     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.988179     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.991451     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.994642     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319753.997349     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.000214     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.003102     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.007305     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.009909     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.012918     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.016116     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.018971     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.022319     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.025555     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.028638     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.032411     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.045719     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.047377     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.048923     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.050418     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.051906     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.053456     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.055037     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.056942     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.058550     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.060158     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.061759     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.063377     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.065120     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.066764     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.068343     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.070098     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.071943     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.073996     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.075632     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.077149     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.078735     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.080407     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.082033     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.083650     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.085474     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.087477     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.089477     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.091383     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.093310     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.095083     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.096732     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.098431     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.100409     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.101986     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.103906     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.105771     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.107843     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.110061     340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.134775     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.136475     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.138083     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.139958     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.141532     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.143249     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.144821     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.146435     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.148455     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.150039     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.151909     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.153832     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.156212     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.158081     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.161573     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.163432     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1726319754.165288     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.167221     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.169304     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.171172     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.173754     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.175818     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.177895     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.179574     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.181338     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.183172     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.184971     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.187756     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.196427     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.197888     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.199130     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.200351     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.201596     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.202832     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.204087     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.205325     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.206859     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.208305     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.209663     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.210922     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.212318     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.213663     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.215259     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.216691     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.217955     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.219390     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.220719     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.222639     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.224612     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.227607     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.233781     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.235713     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.237744     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.239791     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.241697     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.243623     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.245636     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.247677     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.250103     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.252627     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.255194     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.257776     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.259853     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.262419     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.265011     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.266871     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.269668     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.273569     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.276261     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.278977     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.282064     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.286356     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.307269     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.309826     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.311937     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.314305     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.316566     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.318788     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.320951     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.324380     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.327246     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.329597     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.332422     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.334672     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.337437     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.340461     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.343992     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.345973     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.348614     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.351520     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.354377     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.357112     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.360092     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/296\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7806 - loss: 0.5263 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1726319754.366004     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.368919     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319754.371953     338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7815 - loss: 0.5259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1726319764.346983     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.348191     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.349161     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.350290     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.351583     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.352473     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.353370     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.354281     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.355268     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.356338     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.357273     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.358176     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.359132     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.360018     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.360963     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.361916     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.362915     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.363808     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.364785     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.365745     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.366716     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.367676     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.368631     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.369564     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.370897     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.371916     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.373146     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.374153     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.375040     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.375993     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.376941     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.377907     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.378910     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.379932     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.380993     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.382098     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.383092     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.384101     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.385453     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.386646     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.397727     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.398793     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.399626     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.400509     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.401422     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.402331     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.403296     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.404151     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.404960     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.406051     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.407094     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.408059     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.408959     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.409964     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.410815     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.411646     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.412557     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.413389     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.414300     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.415201     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.416041     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.416880     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.417707     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.418538     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.419390     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.420227     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.421105     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.422074     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.423259     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.424236     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.425144     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.426034     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.440260     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.441316     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.442248     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.443137     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.444078     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.445082     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.446061     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.446990     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.448075     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.449134     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.450162     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.451136     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.452020     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.452901     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.454002     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.455202     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.456291     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.457306     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.458228     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.459107     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.460269     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.468982     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.470025     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.470861     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.471871     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.472966     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.473813     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.474626     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.475446     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.476338     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.477160     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.477979     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.478801     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.479689     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.480559     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.481470     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.482333     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.483222     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.484131     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.484993     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.485862     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.486772     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.487862     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.488909     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.490229     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.519401     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.520456     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.521393     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.522561     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.523582     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.524499     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.525398     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.526337     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.527282     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.528222     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.529183     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.530179     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.531137     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.532124     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.533255     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.534231     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.535238     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.536392     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.537414     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.539049     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.540269     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.541263     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.542877     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.544225     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7815 - loss: 0.5259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1726319764.552538     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.554006     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.555114     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.556454     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.557780     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.558879     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.559929     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.561177     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.562492     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.563721     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.564777     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.565722     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.566697     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.567806     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.568837     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.569784     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.570862     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.571958     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.573131     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.574319     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.575435     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.576531     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.577877     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.578902     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.579996     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.581384     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.583041     341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.675812     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.677482     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.679704     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.681307     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.682963     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.684539     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.686223     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.688115     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.690042     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.691810     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.693761     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.695450     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.697442     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.699084     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.700847     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.702696     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.704846     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.707282     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.709274     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.711279     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.713333     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.715487     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.717818     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.719760     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.721941     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.724451     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.726676     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.728930     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.731513     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.734072     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.736999     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.740289     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.743272     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.754942     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.757646     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.759076     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.761710     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.763076     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.764576     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.766308     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.767626     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.768870     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.770082     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.771363     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.772662     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.774592     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.775936     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.777254     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.778529     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.779865     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.781071     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.782282     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.783805     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.785261     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.786748     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.788024     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.789664     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.790991     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.792349     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.794162     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.796044     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.797676     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.799222     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.800966     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319764.803511     336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.7815 - loss: 0.5259 - val_accuracy: 0.7812 - val_loss: 0.5261\n",
      "Epoch 2/1000\n",
      "\u001b[1m  1/296\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.7891 - loss: 0.5144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1726319766.102486     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.103838     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.105452     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.106903     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.108077     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.109277     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.110512     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.111789     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.113052     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.114270     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.115605     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.116801     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.118198     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.119396     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.120631     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.121981     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.123710     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.125111     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.126606     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.128141     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.129612     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.131175     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.132790     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.134206     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.135688     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.137118     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.138638     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.140426     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.142217     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.143868     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.145685     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.147362     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.149167     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.160385     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.161734     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.162832     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.163940     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.164906     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.165888     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.166912     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.167909     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.168922     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.169896     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.170880     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.171896     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.173290     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.174404     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.175461     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.176700     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.177804     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.178838     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.179890     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.180985     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.182048     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.183090     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.184073     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.185121     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.186164     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.187264     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.188339     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.189653     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.190829     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.192046     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.193147     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.194449     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.195770     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.196988     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.198225     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726319766.199468     335 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7809 - loss: 0.5267 - val_accuracy: 0.7812 - val_loss: 0.5281\n",
      "Epoch 3/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7794 - loss: 0.5292 - val_accuracy: 0.7812 - val_loss: 0.5257\n",
      "Epoch 4/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7818 - loss: 0.5256 - val_accuracy: 0.7812 - val_loss: 0.5279\n",
      "Epoch 5/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7832 - loss: 0.5240 - val_accuracy: 0.7812 - val_loss: 0.5257\n",
      "Epoch 6/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7808 - loss: 0.5267 - val_accuracy: 0.7812 - val_loss: 0.5261\n",
      "Epoch 7/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7820 - loss: 0.5250 - val_accuracy: 0.7812 - val_loss: 0.5268\n",
      "Epoch 8/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7798 - loss: 0.5276 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 9/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7785 - loss: 0.5293 - val_accuracy: 0.7812 - val_loss: 0.5266\n",
      "Epoch 10/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7785 - loss: 0.5293 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 11/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7812 - loss: 0.5261 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 12/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7803 - loss: 0.5270 - val_accuracy: 0.7812 - val_loss: 0.5264\n",
      "Epoch 13/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.7823 - loss: 0.5243 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 14/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.7804 - loss: 0.5267 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 15/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.7782 - loss: 0.5296 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 16/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7837 - loss: 0.5222 - val_accuracy: 0.7812 - val_loss: 0.5260\n",
      "Epoch 17/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7819 - loss: 0.5248 - val_accuracy: 0.7812 - val_loss: 0.5258\n",
      "Epoch 18/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7824 - loss: 0.5240 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 19/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7815 - loss: 0.5257 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 20/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7824 - loss: 0.5242 - val_accuracy: 0.7812 - val_loss: 0.5257\n",
      "Epoch 21/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7812 - loss: 0.5255 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 22/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7848 - loss: 0.5212 - val_accuracy: 0.7812 - val_loss: 0.5258\n",
      "Epoch 23/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7815 - loss: 0.5253 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 24/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7820 - loss: 0.5246 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 25/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7819 - loss: 0.5248 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 26/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7840 - loss: 0.5221 - val_accuracy: 0.7812 - val_loss: 0.5257\n",
      "Epoch 27/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7790 - loss: 0.5283 - val_accuracy: 0.7812 - val_loss: 0.5258\n",
      "Epoch 28/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7835 - loss: 0.5225 - val_accuracy: 0.7812 - val_loss: 0.5261\n",
      "Epoch 29/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7803 - loss: 0.5269 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 30/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7841 - loss: 0.5218 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 31/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7831 - loss: 0.5232 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 32/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7816 - loss: 0.5251 - val_accuracy: 0.7812 - val_loss: 0.5256\n",
      "Epoch 33/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7783 - loss: 0.5292 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 34/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.7826 - loss: 0.5238 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 35/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7805 - loss: 0.5265 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 36/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7825 - loss: 0.5238 - val_accuracy: 0.7812 - val_loss: 0.5256\n",
      "Epoch 37/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7799 - loss: 0.5273 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 38/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7829 - loss: 0.5234 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 39/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7773 - loss: 0.5304 - val_accuracy: 0.7812 - val_loss: 0.5257\n",
      "Epoch 40/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7820 - loss: 0.5246 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 41/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7817 - loss: 0.5249 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 42/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7796 - loss: 0.5276 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 43/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7829 - loss: 0.5234 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 44/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7816 - loss: 0.5250 - val_accuracy: 0.7812 - val_loss: 0.5257\n",
      "Epoch 45/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7810 - loss: 0.5259 - val_accuracy: 0.7812 - val_loss: 0.5265\n",
      "Epoch 46/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7796 - loss: 0.5280 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 47/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7771 - loss: 0.5306 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 48/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7814 - loss: 0.5252 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 49/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7849 - loss: 0.5211 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 50/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7813 - loss: 0.5255 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 51/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7797 - loss: 0.5275 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 52/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7798 - loss: 0.5273 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 53/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7797 - loss: 0.5275 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 54/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7798 - loss: 0.5272 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 55/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7814 - loss: 0.5252 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 56/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7827 - loss: 0.5237 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 57/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7822 - loss: 0.5244 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 58/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7829 - loss: 0.5232 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 59/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7795 - loss: 0.5277 - val_accuracy: 0.7812 - val_loss: 0.5256\n",
      "Epoch 60/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7824 - loss: 0.5240 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 61/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7848 - loss: 0.5209 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 62/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7852 - loss: 0.5203 - val_accuracy: 0.7812 - val_loss: 0.5257\n",
      "Epoch 63/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7787 - loss: 0.5286 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 64/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7833 - loss: 0.5229 - val_accuracy: 0.7812 - val_loss: 0.5255\n",
      "Epoch 65/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.7795 - loss: 0.5276 - val_accuracy: 0.7812 - val_loss: 0.5254\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=128,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f117ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e53e616",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'attention'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mattention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Attention\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'attention'"
     ]
    }
   ],
   "source": [
    "from attention import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cb05471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,929,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │  \u001b[38;5;34m1,929,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m197,632\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m82,176\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m738\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ attention_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,269,313</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,269,313\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,269,313</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,269,313\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Input, Flatten, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Attention\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 입력 레이어\n",
    "inputs = Input(shape=(max_len,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "x = Embedding(input_dim=word_size, output_dim=64)(inputs)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# 양방향 LSTM과 Attention\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "attention = Attention()([x, x])\n",
    "x = Dropout(0.5)(attention)\n",
    "\n",
    "# 추가적인 LSTM과 Attention\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "attention = Attention()([x, x])\n",
    "x = Dropout(0.5)(attention)\n",
    "\n",
    "# 차원 축소\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Dense 레이어\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# 출력 레이어\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ae40c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelpath = \"./model/hotels_review_Attention.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath=modelpath, save_best_only=True)\n",
    "earlystop = EarlyStopping(patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b060af9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 245ms/step - accuracy: 0.7829 - loss: 0.5255 - val_accuracy: 0.7372 - val_loss: 0.4936\n",
      "Epoch 2/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 242ms/step - accuracy: 0.8041 - loss: 0.4296 - val_accuracy: 0.8477 - val_loss: 0.3683\n",
      "Epoch 3/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 240ms/step - accuracy: 0.8632 - loss: 0.3318 - val_accuracy: 0.8728 - val_loss: 0.3166\n",
      "Epoch 4/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 240ms/step - accuracy: 0.8775 - loss: 0.2960 - val_accuracy: 0.8734 - val_loss: 0.3039\n",
      "Epoch 5/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 247ms/step - accuracy: 0.8993 - loss: 0.2564 - val_accuracy: 0.8798 - val_loss: 0.2973\n",
      "Epoch 6/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 273ms/step - accuracy: 0.9066 - loss: 0.2404 - val_accuracy: 0.8805 - val_loss: 0.2879\n",
      "Epoch 7/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 237ms/step - accuracy: 0.9174 - loss: 0.2207 - val_accuracy: 0.8805 - val_loss: 0.2987\n",
      "Epoch 8/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 239ms/step - accuracy: 0.9209 - loss: 0.2110 - val_accuracy: 0.8620 - val_loss: 0.3283\n",
      "Epoch 9/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 238ms/step - accuracy: 0.9255 - loss: 0.2003 - val_accuracy: 0.8747 - val_loss: 0.3331\n",
      "Epoch 10/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 235ms/step - accuracy: 0.9330 - loss: 0.1837 - val_accuracy: 0.8737 - val_loss: 0.3288\n",
      "Epoch 11/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 238ms/step - accuracy: 0.9396 - loss: 0.1671 - val_accuracy: 0.8760 - val_loss: 0.3306\n",
      "Epoch 12/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 236ms/step - accuracy: 0.9428 - loss: 0.1629 - val_accuracy: 0.8732 - val_loss: 0.3309\n",
      "Epoch 13/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 237ms/step - accuracy: 0.9463 - loss: 0.1525 - val_accuracy: 0.8690 - val_loss: 0.3665\n",
      "Epoch 14/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 236ms/step - accuracy: 0.9495 - loss: 0.1445 - val_accuracy: 0.8692 - val_loss: 0.3474\n",
      "Epoch 15/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 239ms/step - accuracy: 0.9516 - loss: 0.1375 - val_accuracy: 0.8636 - val_loss: 0.3771\n",
      "Epoch 16/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 238ms/step - accuracy: 0.9533 - loss: 0.1376 - val_accuracy: 0.8717 - val_loss: 0.3845\n",
      "Epoch 17/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 236ms/step - accuracy: 0.9538 - loss: 0.1325 - val_accuracy: 0.8675 - val_loss: 0.3995\n",
      "Epoch 18/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 239ms/step - accuracy: 0.9582 - loss: 0.1237 - val_accuracy: 0.8653 - val_loss: 0.4217\n",
      "Epoch 19/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 238ms/step - accuracy: 0.9604 - loss: 0.1140 - val_accuracy: 0.8636 - val_loss: 0.4193\n",
      "Epoch 20/1000\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 238ms/step - accuracy: 0.9602 - loss: 0.1135 - val_accuracy: 0.8638 - val_loss: 0.4331\n",
      "Epoch 21/1000\n",
      "\u001b[1m170/296\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 206ms/step - accuracy: 0.9633 - loss: 0.1060"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearlystop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=128,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2127930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce8d83",
   "metadata": {},
   "source": [
    "# 머신러닝 나이브 베이즈와 비교를 위해 비교 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a838af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a137129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x):\n",
    "    token = mecab.morphs(x)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e4a2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data['description']\n",
    "y = train_data['isgood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bff6fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf_cv = TfidfVectorizer(tokenizer=tokenizer, max_df=0.8, min_df=4, ngram_range=(1,3))\n",
    "X_tfidf = tfidf_cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5593f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tfidf, y, test_size=0.4, random_state=7)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7044116c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.31      0.47      2321\n",
      "           1       0.84      0.99      0.91      8472\n",
      "\n",
      "    accuracy                           0.85     10793\n",
      "   macro avg       0.88      0.65      0.69     10793\n",
      "weighted avg       0.86      0.85      0.82     10793\n",
      "\n",
      "======================================== test result ========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.29      0.45      2327\n",
      "           1       0.84      0.99      0.91      8466\n",
      "\n",
      "    accuracy                           0.84     10793\n",
      "   macro avg       0.88      0.64      0.68     10793\n",
      "weighted avg       0.86      0.84      0.81     10793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "pred = mnb.predict(X_valid)\n",
    "print(classification_report(y_valid, pred))\n",
    "test_pred = mnb.predict(X_test)\n",
    "print(\"=\"*40, \"test result\", \"=\"*40)\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91e829",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a1d364d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/tfidf_cv_hotels_model']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(mecab, \"./model/mecab_hotels_model\")\n",
    "joblib.dump(mnb, \"./model/Naive Bayes_hotels_model\")\n",
    "joblib.dump(tfidf_cv, \"./model/tfidf_cv_hotels_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cdaec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe274f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41193aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbda90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4fa9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b7010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
