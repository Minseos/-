{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025c6475",
   "metadata": {},
   "source": [
    "# 스테이블디퓨전으로_이미지생성서비스_만들기\n",
    "* 간단한 스케치를 기반으로 이미지 생성\n",
    "* 스케치가 되어있는 이미지를 업로드해서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfed78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873c7a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f195d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import IO\n",
    "import gradio as gr\n",
    "import requests\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0b955",
   "metadata": {},
   "source": [
    "# 스케치 투 이미지 생성 UI 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac5c528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 프롬프트 입력\")\n",
    "    with gr.Row():\n",
    "        prompt = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Row():\n",
    "        negative_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
    "        \n",
    "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Tab(\"Canvas\"):\n",
    "                with gr.Row():\n",
    "                    canvas = gr.Image(\n",
    "                        label = \"Draw\",\n",
    "                        source = 'canvas',\n",
    "                        image_mode = 'RGB',\n",
    "                        tool = 'color-sketch',\n",
    "                        interactive = True,  # Corrected here\n",
    "                        width = WIDTH,\n",
    "                        height = HEIGHT,\n",
    "                        shape = (WIDTH, HEIGHT),\n",
    "                        brush_radius = 20,\n",
    "                        type = 'pil'\n",
    "                    )\n",
    "               \n",
    "                with gr.Row():\n",
    "                    canvas_run_btn = gr.Button(value=\"Generate\")\n",
    "            \n",
    "            with gr.Tab(\"File\"):\n",
    "                with gr.Row():\n",
    "                    file = gr.Image(\n",
    "                        label = \"Upload\",\n",
    "                        source = 'upload',\n",
    "                        image_mode = 'RGB',\n",
    "                        tool = 'color-sketch',\n",
    "                        interactive = True,  # Corrected here\n",
    "                        width = WIDTH,\n",
    "                        height = HEIGHT,\n",
    "                        shape = (WIDTH, HEIGHT),\n",
    "                        type = 'pil'\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    file_run_btn = gr.Button(value=\"Generate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18f678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "Running on public URL: https://1ccb199e5d9478c378.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de283ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308c778",
   "metadata": {},
   "source": [
    "# 모델 다운로드 UI 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c2cf24e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label = \"모델 URL\", placeholder = \"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value = \"모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(label = \"모델 파일\")\n",
    "        \n",
    "    download_model_btn.click(\n",
    "        download_model,\n",
    "        [model_url],\n",
    "        [model_file]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7c2e668",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://5573f05e9ea6ad8e29.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "models/disneyPixarCartoon_v10.safetensors: 100%|██████████████████████| 3.95G/3.95G [10:59<00:00, 6.44MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File downloaded: models/disneyPixarCartoon_v10.safetensors\n"
     ]
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfe86557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832377fd",
   "metadata": {},
   "source": [
    "# 모델 다운로드 기능 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1862ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# 전역 변수로 모델 경로와 파일명을 저장\n",
    "MODEL_PATH = None\n",
    "\n",
    "#URL로부터 파일 다운로드 함수\n",
    "def download_from_url(url, file_path, chunk_size=1024):\n",
    "    try:\n",
    "        resp = requests.get(url, stream=True)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e\n",
    "        \n",
    "    total = int(resp.headers.get('content-length', 0)) # 파일 크기 추출\n",
    "    with open(file_path, 'wb') as file, tqdm(desc = file_path, total=total, unit = 'iB', unit_scale=True, \n",
    "                                            unit_divisor=1024) as bar:\n",
    "        for data in resp.iter_content(chunk_size = chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "            \n",
    "\n",
    "# 모델을 다운로드하고 경로를 기억하는 함수\n",
    "def download_model(url: str) -> str :\n",
    "    global MODEL_PATH # 전역변수 사용해서 경로를 기억\n",
    "    \n",
    "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout = 6000)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e\n",
    "        \n",
    "    download_url = response.json()['modelVersions'][0]['downloadUrl']\n",
    "    filename = response.json()['modelVersions'][0]['files'][0]['name']\n",
    "    \n",
    "    file_path = f\"models/{filename}\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[INFO] File already exists : {file_path}\")\n",
    "        MODEL_PATH = file_path # 모델 경로 기억\n",
    "        return file_path\n",
    "    \n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    download_from_url(download_url, file_path)\n",
    "    print(f\"[INFO] File downloaded: {file_path}\")\n",
    "    \n",
    "    \n",
    "    # 모델 경로 기억\n",
    "    MODEL_PATH = file_path\n",
    "    return file_path\n",
    "       \n",
    "# ./models 폴더에서 가장 최근에 수정된 모델 파일 찾기\n",
    "def find_latest_model_in_directory(directory):\n",
    "    model_files = glob.glob(f\"{directory}/*.safetensors\")\n",
    "    if not model_files:\n",
    "        return None\n",
    "    \n",
    "    # 가장 최근에 수정된 모델 파일 선택\n",
    "    latest_model = max(model_files, key=os.path.getmtime)\n",
    "    return latest_model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57793e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "283125cc",
   "metadata": {},
   "source": [
    "# 다운로드한 모델 불러와서 초기화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0c134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pipeline():\n",
    "    global MODEL_PATH\n",
    "    \n",
    "    if MODEL_PATH is None:\n",
    "        MODEL_PATH = find_latest_model_in_directory(\"./models/\")\n",
    "    if MODEL_PATH is None:\n",
    "        return \"Error : No model found in ./models\"\n",
    "    \n",
    "    global PIPELINE\n",
    "    \n",
    "    try:\n",
    "        PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
    "            MODEL_PATH,\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True,\n",
    "        ).to('cpu')\n",
    "        print(\"[INFO] Initialized pipeline\")\n",
    "        return \"Model Loaded\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89177031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        is_model_check = gr.Textbox(label = \"Model Load Check\", value=\"Model Not Loaded\")\n",
    "        \n",
    "    load_model_btn.click(\n",
    "        init_pipeline,\n",
    "        None,\n",
    "        [is_model_check]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59819966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://935b01a7a2607bb2fc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 11 files: 100%|█████████████████████████████████████████████████| 11/11 [00:00<00:00, 58549.93it/s]\n",
      "Loading pipeline components...:   0%|                                                 | 0/6 [00:00<?, ?it/s]/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint were not used when initializing CLIPTextModel: \n",
      " ['text_model.embeddings.position_ids']\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████| 6/6 [00:34<00:00,  5.77s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initialized pipeline\n"
     ]
    }
   ],
   "source": [
    "app.queue().launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1c1ac4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'app' is not defined"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3610e",
   "metadata": {},
   "source": [
    "# 스케치 투 이미지 생성기능 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch_to_image(sketch, prompt, negative_prompt):\n",
    "    global PIPELINE\n",
    "    if PIPELINE is None:\n",
    "        return \"Error Pipeline is not initialized\"\n",
    "    \n",
    "    prompt = [prompt]\n",
    "    negative_prompt = [negative_prompt]\n",
    "    \n",
    "    images = [sketch]* len(prompt)\n",
    "    \n",
    "    try:\n",
    "        # 이미지 생성\n",
    "        result = PIPELINE(\n",
    "            image = images,\n",
    "            prompt = prompt,\n",
    "            negative_prompt = negative_prompt,\n",
    "            height = height,\n",
    "            width = width,\n",
    "            num_images_per_prompt = 4,\n",
    "            num_inference_steps = 10,\n",
    "            strength=0.7\n",
    "        ).images\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "#     # GPU 메모리 캐시 비우기\n",
    "#     with torch.cuda.device(\"cuda\")\n",
    "#         torch.cuda.empty_chache()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf7af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9e0fc83",
   "metadata": {},
   "source": [
    "# 이미지 생성 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46672517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import requests\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "from typing import IO\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fef8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "\n",
    "# 전역 변수로 모델 경로와 파일명을 저장\n",
    "MODEL_PATH = None\n",
    "PIPELINE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18bcb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# URL로부터 파일 다운로드 함수\n",
    "def download_from_url(url, file_path, chunk_size=1024):\n",
    "    try:\n",
    "        resp = requests.get(url, stream = True)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e\n",
    "\n",
    "    total = int(resp.headers.get('content-length', 0))  # 파일 크기 추출\n",
    "    with open(file_path, 'wb') as file, tqdm(desc=file_path, total=total, unit='iB', unit_scale=True,\n",
    "                                            unit_divisor = 1024) as bar:\n",
    "        for data in resp.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "\n",
    "\n",
    "# 모델을 다운로드하고 경로를 기억하는 함수\n",
    "def download_model(url: str) -> str:\n",
    "    global MODEL_PATH    # 전역 변수를 사용해서 경로를 파악\n",
    "\n",
    "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout = 6000)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e\n",
    "\n",
    "    download_url = response.json()['modelVersions'][0]['downloadUrl']\n",
    "    filename = response.json()['modelVersions'][0]['files'][0]['name']\n",
    "\n",
    "    file_path = f\"models/{filename}\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[INFO] File already exists: {file_path}\")\n",
    "        MODEL_PATH = file_path   # 모델 경로 기억\n",
    "        return file_path\n",
    "\n",
    "    os.makedirs(\"models\", exist_ok = True)\n",
    "    download_from_url(download_url, file_path)\n",
    "    print(f\"[INFO] File downloaded: {file_path}\")\n",
    "\n",
    "# 모델 경로 기억\n",
    "    MODEL_PATH = file_path\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# ./models 폴더에서 가장 최근에 수정된 모델 파일 찾기\n",
    "def find_latest_model_in_directory(directory):\n",
    "    model_files = glob.glob(f\"{directory}/*.safetensors\")\n",
    "    if not model_files:\n",
    "        return None\n",
    "\n",
    "\n",
    "# 가장 최근에 수정된 모델 파일 선택\n",
    "    latest_model = max(model_files, key =os.path.getmtime)\n",
    "    return latest_model\n",
    "\n",
    "\n",
    "def init_pipeline():\n",
    "    global MODEL_PATH\n",
    "\n",
    "    if MODEL_PATH is None:\n",
    "        MODEL_PATH = find_latest_model_in_directory(\"./models\")\n",
    "    if MODEL_PATH is None:\n",
    "        return \"Error: No model found in ./models\"\n",
    "\n",
    "    global PIPELINE\n",
    "\n",
    "    try:\n",
    "        PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
    "                MODEL_PATH,\n",
    "                torch_dtype = torch.float16,\n",
    "                variant = \"fp16\",\n",
    "                use_safetensors = True,\n",
    "        ).to('cuda')\n",
    "        print(\"[INFO] Initialized pipeline\")\n",
    "        return \"Model Loaded!\"\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "\n",
    "#모델을 불러와서 모델에서 이미지 생성하는\n",
    "def sketch_to_image(sketch, prompt, negative_prompt):\n",
    "    global PIPELINE\n",
    "    if PIPELINE is None:\n",
    "        return \"Error Pipeline is not initialized\"\n",
    "    prompt = [prompt]\n",
    "    negative_prompt =[negative_prompt]\n",
    "\n",
    "    images =[sketch] * len(prompt)\n",
    "\n",
    "    try:\n",
    "        #이미지 생성\n",
    "        result = PIPELINE(\n",
    "            image=images,\n",
    "            prompt=prompt,\n",
    "            negative_prompt= negative_prompt,\n",
    "            height= height,\n",
    "            width=width,\n",
    "            num_images_per_prompt=4,\n",
    "            num_inference_steps=20,\n",
    "            strength = 0.7\n",
    "        ).images\n",
    "    except Excption as e:\n",
    "        print(e)\n",
    "        return e\n",
    "        #gpu메모리 캐시 비우기\n",
    "        #with torch.cuda.device(\"cuda\")\n",
    "        #torch.cuda.empty_cache()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc1dc1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://48425f5271ea95e817.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/gradio/routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/gradio/blocks.py\", line 1427, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/gradio/blocks.py\", line 1109, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2405, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 914, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/gradio/utils.py\", line 706, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_105983/2142728530.py\", line 64, in init_pipeline\n",
      "    MODEL_PATH = find_latest_model_in_directory(\"./models/\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_105983/2142728530.py\", line 57, in find_latest_model_in_directory\n",
      "    return latest_model\n",
      "           ^^^^^^^^^^^^\n",
      "NameError: name 'latest_model' is not defined\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "\n",
    "    # 모델 다운로드 블록\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label = \"모델 URL\", placeholder = \"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value = \"모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(label = \"모델 파일\")\n",
    "\n",
    "\n",
    "    # 모델 불러오기 블록\n",
    "    gr.Markdown(\"## 모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not Loaded\")\n",
    "\n",
    "\n",
    "    # 프롬프트 입력 블록\n",
    "    gr.Markdown(\"## 프롬프트 입력\")\n",
    "    with gr.Row():\n",
    "        prompt = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Row():\n",
    "        n_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
    "\n",
    "\n",
    "    # 스케치에서 이미지 생성 블록\n",
    "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Tab(\"Canvas\"):\n",
    "                with gr.Row():\n",
    "                    canvas = gr.Image(\n",
    "                        label = \"Draw\",\n",
    "                        source = \"canvas\",\n",
    "                        image_mode = 'RGB',\n",
    "                        tool = 'color-sketch',\n",
    "                        interactive = True,\n",
    "                        width = WIDTH,\n",
    "                        height = HEIGHT,\n",
    "                        shape = (WIDTH, HEIGHT),\n",
    "                        brush_radius = 20,\n",
    "                        type = 'pil'\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    canvas_run_btn = gr.Button(value = \"Generate\")\n",
    "\n",
    "            with gr.Tab(\"File\"):\n",
    "                with gr.Row():\n",
    "                    file = gr.Image(\n",
    "                        label = \"Upload\",\n",
    "                        source = \"upload\",\n",
    "                        image_mode = 'RGB',\n",
    "                        tool = 'color-sketch',\n",
    "                        interactive = True,\n",
    "                        width = WIDTH,\n",
    "                        height = HEIGHT,\n",
    "                        shape = (WIDTH, HEIGHT),\n",
    "                        type = 'pil'\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    file_run_btn = gr.Button(value = \"Generate\")\n",
    "\n",
    "        # 결과 이미지 갤러리\n",
    "        with gr.Column():\n",
    "            result_gallery = gr.Gallery(label=\"Output\", height=512)\n",
    "\n",
    "\n",
    "    # 모델 다운로드 실행\n",
    "    download_model_btn.click(\n",
    "        download_model,\n",
    "        [model_url],\n",
    "        [model_file]\n",
    "        )\n",
    "    # 모델 로드 실행\n",
    "    load_model_btn.click(\n",
    "        init_pipeline,\n",
    "        None,\n",
    "        [is_model_check]\n",
    "        )\n",
    "    # Canvas 에서 이미지 생성 버튼 실행\n",
    "    canvas_run_btn.click(\n",
    "        sketch_to_image,\n",
    "        [canvas, prompt, n_prompt],\n",
    "        [result_gallery]\n",
    "        )\n",
    "    # File 업로드에서 이미지 생성 버튼 실행\n",
    "    file_run_btn.click(\n",
    "        sketch_to_image,\n",
    "        [file, prompt, n_prompt],\n",
    "        [result_gallery]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app.queue().launch(inline=False, share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094d262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d385ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe4107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67f6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342bba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781531b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab9bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4acbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6855e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db0ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149d4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ddafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3256ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60847d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85466892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78435248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e3a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae060e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666c56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e85027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3d970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c5a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
