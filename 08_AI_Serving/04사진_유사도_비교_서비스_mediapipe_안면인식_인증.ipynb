{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76e4a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75621d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O embedder.tflite -q https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16a6939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "# Correct image filenames for the downloaded images\n",
    "IMAGE_FILENAMES = ['burger.jpg', 'burger_crop.jpg']\n",
    "\n",
    "# Download the images\n",
    "for name in IMAGE_FILENAMES:\n",
    "  url = f'https://storage.googleapis.com/mediapipe-assets/{name}'\n",
    "  urllib.request.urlretrieve(url, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e45d4d",
   "metadata": {},
   "source": [
    "### 구글 코랩 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09848381",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      5\u001b[0m DESIRED_HEIGHT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m480\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import math\n",
    "\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "def resize_and_show(image):\n",
    "  h, w = image.shape[:2]\n",
    "  if h < w:\n",
    "    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "  else:\n",
    "    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "  cv2_imshow(img)\n",
    "\n",
    "\n",
    "# Preview the images.\n",
    "images = {name: cv2.imread(name) for name in IMAGE_FILENAMES}\n",
    "for name, image in images.items():\n",
    "  print(name)\n",
    "  resize_and_show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f981bf5",
   "metadata": {},
   "source": [
    "### 주피터 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f94e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image1.jpg\n",
      "Failed to load image2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@199.511] global loadsave.cpp:241 findDecoder imread_('image1.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@199.512] global loadsave.cpp:241 findDecoder imread_('image2.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "def resize_and_show(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "    \n",
    "    # Convert BGR to RGB for displaying with matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "\n",
    "# Load and preview the images\n",
    "images = {name: cv2.imread(name) for name in IMAGE_FILENAMES}\n",
    "for name, image in images.items():\n",
    "    if image is not None:\n",
    "        print(f\"Displaying {name}\")\n",
    "        resize_and_show(image)\n",
    "    else:\n",
    "        print(f\"Failed to load {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c132b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727147818.589344   15412 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1727147818.614087   19623 gl_context.cc:357] GL version: 3.1 (OpenGL ES 3.1 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: D3D12 (AMD Radeon(TM) Graphics)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Image decoding failed (can't fopen): image1.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create the Image Embedder\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vision\u001b[38;5;241m.\u001b[39mImageEmbedder\u001b[38;5;241m.\u001b[39mcreate_from_options(options) \u001b[38;5;28;01mas\u001b[39;00m embedder:\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Load the images\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     first_image \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGE_FILENAMES\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     second_image \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mcreate_from_file(IMAGE_FILENAMES[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Generate embeddings for each image\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Image decoding failed (can't fopen): image1.jpg"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# Path to the model file (make sure the embedder.tflite file is in the correct location)\n",
    "base_options = python.BaseOptions(model_asset_path='embedder.tflite')\n",
    "l2_normalize = True  # Whether to L2 normalize the embeddings\n",
    "quantize = True  # Whether to quantize the embeddings\n",
    "options = vision.ImageEmbedderOptions(\n",
    "    base_options=base_options, l2_normalize=l2_normalize, quantize=quantize)\n",
    "\n",
    "# Create the Image Embedder\n",
    "with vision.ImageEmbedder.create_from_options(options) as embedder:\n",
    "\n",
    "    # Load the images\n",
    "    first_image = mp.Image.create_from_file(IMAGE_FILENAMES[0])\n",
    "    second_image = mp.Image.create_from_file(IMAGE_FILENAMES[1])\n",
    "\n",
    "    # Generate embeddings for each image\n",
    "    first_embedding_result = embedder.embed(first_image)\n",
    "    second_embedding_result = embedder.embed(second_image)\n",
    "\n",
    "    # Calculate cosine similarity between the two image embeddings\n",
    "    similarity = vision.ImageEmbedder.cosine_similarity(\n",
    "        first_embedding_result.embeddings[0],\n",
    "        second_embedding_result.embeddings[0]\n",
    "    )\n",
    "\n",
    "    print(f\"Cosine Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bcbb41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Parallel'>: No known documentation group for module 'gradio.mix'\n",
      "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n",
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Series'>: No known documentation group for module 'gradio.mix'\n",
      "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://946a7dd0b02097aab7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727161374.192789   74161 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1727161374.217903   74267 gl_context.cc:357] GL version: 3.1 (OpenGL ES 3.1 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: D3D12 (AMD Radeon(TM) Graphics)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the Image Embedder model\n",
    "base_options = python.BaseOptions(model_asset_path='embedder.tflite')\n",
    "l2_normalize = True\n",
    "quantize = True\n",
    "options = vision.ImageEmbedderOptions(\n",
    "    base_options=base_options, l2_normalize=l2_normalize, quantize=quantize)\n",
    "\n",
    "def process_images(image1, image2):\n",
    "    with vision.ImageEmbedder.create_from_options(options) as embedder:\n",
    "        # Convert to MediaPipe image format\n",
    "        first_image = mp.Image.create_from_file(image1)\n",
    "        second_image = mp.Image.create_from_file(image2)\n",
    "\n",
    "        # Generate embeddings\n",
    "        first_embedding_result = embedder.embed(first_image)\n",
    "        second_embedding_result = embedder.embed(second_image)\n",
    "\n",
    "        # Calculate similarity\n",
    "        similarity = vision.ImageEmbedder.cosine_similarity(\n",
    "            first_embedding_result.embeddings[0],\n",
    "            second_embedding_result.embeddings[0]\n",
    "        )\n",
    "\n",
    "        return f\"Cosine Similarity: {similarity}\"\n",
    "\n",
    "# Gradio interface for selecting two images\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## Upload two images to compare their embeddings\")\n",
    "\n",
    "    with gr.Row():\n",
    "        img1 = gr.Image(label=\"First Image\", type=\"filepath\")\n",
    "        img2 = gr.Image(label=\"Second Image\", type=\"filepath\")\n",
    "\n",
    "    result = gr.Textbox(label=\"Cosine Similarity\")\n",
    "    compare_button = gr.Button(\"Compare\")\n",
    "\n",
    "    # Action for comparing images\n",
    "    compare_button.click(fn=process_images, inputs=[img1, img2], outputs=result)\n",
    "\n",
    "# Launch the app\n",
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22180b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149002a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a77378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605b37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5c12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f61627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480b09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a95422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbd62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d999f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b1223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425cd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e92cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffe4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6cbce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
