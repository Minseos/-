{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUv0oLobvCKp"
   },
   "source": [
    "# Sketch to Image Application\n",
    "\n",
    "Colab 환경에서 스케치 투 이미지 애플리케이션을 만들어봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxIxrPMYvPr1"
   },
   "source": [
    "## 패키지 및 예제 데이터 다운로드하기\n",
    "python package들을 설치합니다. Colab에서 실행하지 않는 경우 이 셀은 실행하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CiswP_Ef97e",
    "outputId": "77825f91-279b-4ec8-f81c-5f72033f6fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-25 05:49:33--  https://raw.githubusercontent.com/mrsyee/dl_apps/main/image_generation/requirements-colab.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 59 [text/plain]\n",
      "Saving to: ‘requirements-colab.txt.1’\n",
      "\n",
      "requirements-colab. 100%[===================>]      59  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-25 05:49:33 (3.31 MB/s) - ‘requirements-colab.txt.1’ saved [59/59]\n",
      "\n",
      "Requirement already satisfied: diffusers==0.26.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 1)) (0.26.2)\n",
      "Requirement already satisfied: accelerate==0.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 2)) (0.31.0)\n",
      "Requirement already satisfied: gradio==3.40.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 5)) (3.40.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (0.24.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (0.4.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.31.0->-r requirements-colab.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.31.0->-r requirements-colab.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.31.0->-r requirements-colab.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.31.0->-r requirements-colab.txt (line 2)) (2.4.1+cu121)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (23.2.1)\n",
      "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.10.5)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.2.2)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.115.0)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: gradio-client>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.27.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.1.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.7.1)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.3.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.10.7)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.1.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.9.2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.0.10)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.30.6)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (11.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.0.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.23.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.4.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.6.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.14.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.26.2->-r requirements-colab.txt (line 1)) (4.66.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.26.2->-r requirements-colab.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.26.2->-r requirements-colab.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.31.0->-r requirements-colab.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.31.0->-r requirements-colab.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (8.1.7)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.38.6)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.26.2->-r requirements-colab.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.20.0)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.31.0->-r requirements-colab.txt (line 2)) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/image_generation/requirements-colab.txt\n",
    "!pip install -r requirements-colab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G96KdmkfeU3Q",
    "outputId": "200c88f6-9d85-4be1-817d-005c059d493c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3y7YKc7HePL_",
    "outputId": "7069ebbd-0447-4a90-ec67-193e9c17c8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.24.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.12.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQzhGixSS7eC"
   },
   "source": [
    "## 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IljnAX2KlAz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import IO\n",
    "\n",
    "import gradio as gr\n",
    "import requests\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa8lhoPRKu-G"
   },
   "source": [
    "## 스케치 투 이미지 생성 UI 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpG7E21tkSnk"
   },
   "outputs": [],
   "source": [
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 프롬프트 입력\")\n",
    "    with gr.Row():\n",
    "        prompt = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Row():\n",
    "        n_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
    "\n",
    "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Tab(\"Canvas\"):\n",
    "                with gr.Row():\n",
    "                    canvas = gr.Image(\n",
    "                        label=\"Draw\",\n",
    "                        source=\"canvas\",\n",
    "                        image_mode=\"RGB\",\n",
    "                        tool=\"color-sketch\",\n",
    "                        interactive=True,\n",
    "                        width=WIDTH,\n",
    "                        height=HEIGHT,\n",
    "                        shape=(WIDTH, HEIGHT),\n",
    "                        brush_radius=20,\n",
    "                        type=\"pil\",\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    canvas_run_btn = gr.Button(value=\"Generate\")\n",
    "\n",
    "            with gr.Tab(\"File\"):\n",
    "                with gr.Row():\n",
    "                    file = gr.Image(\n",
    "                        label=\"Upload\",\n",
    "                        source=\"upload\",\n",
    "                        image_mode=\"RGB\",\n",
    "                        tool=\"color-sketch\",\n",
    "                        interactive=True,\n",
    "                        width=WIDTH,\n",
    "                        height=HEIGHT,\n",
    "                        shape=(WIDTH, HEIGHT),\n",
    "                        type=\"pil\",\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    file_run_btn = gr.Button(value=\"Generate\")\n",
    "\n",
    "        with gr.Column():\n",
    "            result_gallery = gr.Gallery(label=\"Output\", height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJiCOxqWkm-s",
    "outputId": "970d1bba-951e-4dbf-f00b-db754021bbb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://7c45bb78413bf76a33.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFQdzntYkolK",
    "outputId": "168bc1af-2fbc-4bb3-846d-821091368a65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fiop_vbXkqeZ"
   },
   "source": [
    "## 모델 다운로드 UI 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDzXlEk08KB3"
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label=\"모델 URL\", placeholder=\"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value=\"모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(label=\"모델 파일\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g57Gecpx-43U",
    "outputId": "05e93a1a-df2c-4c2f-c1a3-04e30def3a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://a05a0214b3e8f6614f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJYBR55T-6Zn",
    "outputId": "fdc8908d-9e63-4eb2-8e71-f7631c865f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBlThieTBJYa"
   },
   "source": [
    "## 모델 다운로드 기능 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-N5CvL0CQXFp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# 전역 변수로 모델 경로와 파일명을 저장\n",
    "MODEL_PATH = None\n",
    "\n",
    "# 모델을 다운로드하고 경로를 기억하는 함수\n",
    "def download_model(url: str) -> str:\n",
    "    global MODEL_PATH  # 전역 변수를 사용해서 경로를 기억\n",
    "\n",
    "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout=600)\n",
    "    except Exception as err:\n",
    "        print(f\"[ERROR] {err}\")\n",
    "        raise err\n",
    "\n",
    "    download_url = response.json()[\"modelVersions\"][0][\"downloadUrl\"]\n",
    "    filename = response.json()[\"modelVersions\"][0][\"files\"][0][\"name\"]\n",
    "\n",
    "    file_path = f\"models/{filename}\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[INFO] File already exists: {file_path}\")\n",
    "        MODEL_PATH = file_path  # 모델 경로 기억\n",
    "        return file_path\n",
    "\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    download_from_url(download_url, file_path)\n",
    "    print(f\"[INFO] File downloaded: {file_path}\")\n",
    "\n",
    "    # 모델 경로 기억\n",
    "    MODEL_PATH = file_path\n",
    "    return file_path\n",
    "\n",
    "# ./models 폴더에서 가장 최근에 수정된 모델 파일 찾기\n",
    "def find_latest_model_in_directory(directory: str) -> str:\n",
    "    model_files = glob.glob(f\"{directory}/*.safetensors\")\n",
    "    if not model_files:\n",
    "        return None\n",
    "\n",
    "     # 가장 최근에 수정된 모델 파일 선택\n",
    "    latest_model = max(model_files, key=os.path.getmtime)\n",
    "    return latest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0IbkRIcRD-b"
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label=\"모델 URL\", placeholder=\"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value=\"모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(label=\"모델 파일\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vz1-B1ZTTUKX",
    "outputId": "86e7acc2-421d-43ee-8a3a-b4b88bb2c0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://80939d179a855ac4db.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.queue().launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQ3DdaUeTVfV",
    "outputId": "d4362b9c-87f7-4a88-96c6-95a9b6072cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO3V8z6-QX__"
   },
   "source": [
    "## 모델 불러오기 UI 및 기능 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Tb3Ly_PogVu"
   },
   "outputs": [],
   "source": [
    "# 다운로드된 모델을 불러오는 함수\n",
    "def init_pipeline() -> str:\n",
    "    global MODEL_PATH  # 전역 변수를 사용\n",
    "\n",
    "    if MODEL_PATH is None:\n",
    "        # MODEL_PATH가 없으면 ./models에서 모델을 찾음\n",
    "        print(\"[INFO] No model path found, searching ./models directory...\")\n",
    "        MODEL_PATH = find_latest_model_in_directory(\"./models\")\n",
    "\n",
    "    if MODEL_PATH is None:\n",
    "        return \"Error: No model found in ./models directory\"\n",
    "\n",
    "    print(f\"[INFO] Initialize pipeline with model: {MODEL_PATH}\")\n",
    "    global PIPELINE\n",
    "\n",
    "    try:\n",
    "        PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
    "            MODEL_PATH,\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True,\n",
    "        ).to(\"cuda\")\n",
    "        print(\"[INFO] Initialized pipeline\")\n",
    "        return \"Model Loaded!\"\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load model: {e}\")\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcxCcRYCsuxr"
   },
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 설정\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not Loaded\")\n",
    "\n",
    "    download_model_btn.click(\n",
    "        download_model,\n",
    "        [model_url],\n",
    "        [model_file],\n",
    "    )\n",
    "    load_model_btn.click(\n",
    "        init_pipeline,\n",
    "        None,  # 모델을 불러올 때는 별도의 입력이 필요하지 않음\n",
    "        [is_model_check],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfUumDF3A-IN",
    "outputId": "43773410-7b6a-4f6b-a6ab-f6a0b2c0ec16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://1caddbeb8d10e68ab0.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.queue().launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bKanmd2A-lB",
    "outputId": "d213d8ad-ced4-4ecd-9764-dbef61d750be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo8u_NmL-Q2_"
   },
   "source": [
    "## 스케치 투 이미지 생성 기능 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmF6CY38-hdx"
   },
   "outputs": [],
   "source": [
    "def sketch_to_image(sketch: Image.Image, prompt: str, negative_prompt: str):\n",
    "    width, height = sketch.size\n",
    "    images =  PIPELINE(\n",
    "        image=sketch,\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_images_per_prompt=4,\n",
    "        num_inference_steps=20,\n",
    "        strength=0.7,\n",
    "    ).images\n",
    "\n",
    "    with torch.cuda.device(\"cuda\"):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gv6Nh8NzBJYc",
    "outputId": "dedfe244-0813-4735-f615-37f28470b391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Gradio app ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:841: UserWarning: Expected 0 arguments for function <function init_pipeline at 0x7ff37c697490>, received 1.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:849: UserWarning: Expected maximum 0 arguments for function <function init_pipeline at 0x7ff37c697490>, received 1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Gradio app ready\")\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# 스케치 to 이미지 애플리케이션\")\n",
    "\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label=\"Model Link\", placeholder=\"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value=\"Download model\")\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(label=\"Model File\")\n",
    "\n",
    "    gr.Markdown(\"## 모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        load_model_btn = gr.Button(value=\"Load model\")\n",
    "    with gr.Row():\n",
    "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not loaded\")\n",
    "\n",
    "    gr.Markdown(\"## 프롬프트 입력\")\n",
    "    with gr.Row():\n",
    "        prompt = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Row():\n",
    "        n_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
    "\n",
    "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Tab(\"Canvas\"):\n",
    "                with gr.Row():\n",
    "                    canvas = gr.Image(\n",
    "                        label=\"Draw\",\n",
    "                        source=\"canvas\",\n",
    "                        image_mode=\"RGB\",\n",
    "                        tool=\"color-sketch\",\n",
    "                        interactive=True,\n",
    "                        width=WIDTH,\n",
    "                        height=HEIGHT,\n",
    "                        shape=(WIDTH, HEIGHT),\n",
    "                        brush_radius=20,\n",
    "                        type=\"pil\",\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    canvas_run_btn = gr.Button(value=\"Generate\")\n",
    "\n",
    "            with gr.Tab(\"File\"):\n",
    "                with gr.Row():\n",
    "                    file = gr.Image(\n",
    "                        label=\"Upload\",\n",
    "                        source=\"upload\",\n",
    "                        image_mode=\"RGB\",\n",
    "                        tool=\"color-sketch\",\n",
    "                        interactive=True,\n",
    "                        width=WIDTH,\n",
    "                        height=HEIGHT,\n",
    "                        shape=(WIDTH, HEIGHT),\n",
    "                        type=\"pil\",\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    file_run_btn = gr.Button(value=\"Generate\")\n",
    "\n",
    "        with gr.Column():\n",
    "            result_gallery = gr.Gallery(label=\"Output\", height=512)\n",
    "\n",
    "\n",
    "    # Event\n",
    "    download_model_btn.click(\n",
    "        download_model,\n",
    "        [model_url],\n",
    "        [model_file],\n",
    "    )\n",
    "    load_model_btn.click(\n",
    "        init_pipeline,\n",
    "        [model_file],\n",
    "        [is_model_check],\n",
    "    )\n",
    "    canvas_run_btn.click(\n",
    "        sketch_to_image,\n",
    "        [canvas, prompt, n_prompt],\n",
    "        [result_gallery],\n",
    "    )\n",
    "    file_run_btn.click(\n",
    "        sketch_to_image,\n",
    "        [file, prompt, n_prompt],\n",
    "        [result_gallery],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdXq7tMoBJYc",
    "outputId": "6bdc728c-9061-4394-f61a-16a93f942d40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://036c2c2e9b62dbbf54.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.queue().launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7h8BOZuBJYd",
    "outputId": "9f120b96-d9a7-4a80-dee1-2c5617959ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmZOiRmXAIGs"
   },
   "source": [
    "## 최종 App 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OGnSU94Ky37"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import IO\n",
    "import glob\n",
    "import gradio as gr\n",
    "import requests\n",
    "import torch\n",
    "import tempfile\n",
    "# import torch_directml\n",
    "from tqdm import tqdm\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EJHWMdOHh2G"
   },
   "outputs": [],
   "source": [
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "\n",
    "# 전역 변수를 사용하여 모델 경로와 파이프라인 객체를 저장\n",
    "MODEL_PATH = None\n",
    "PIPELINE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roRHRyqRBTqX"
   },
   "outputs": [],
   "source": [
    "# ./models 디렉토리에서 가장 최근에 수정된 모델 파일 찾기\n",
    "def find_latest_model_in_directory(directory: str) -> str:\n",
    "    model_files = glob.glob(f\"{directory}/*.safetensors\")\n",
    "    if not model_files:\n",
    "        return None\n",
    "\n",
    "    # 가장 최근에 수정된 모델 파일 선택\n",
    "    latest_model = max(model_files, key=os.path.getmtime)\n",
    "    return latest_model\n",
    "\n",
    "# 모델 다운로드 함수\n",
    "def download_model(url: str) -> str:\n",
    "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout=600)\n",
    "        response.raise_for_status()  # 요청 상태 확인\n",
    "    except Exception as err:\n",
    "        print(f\"[ERROR] {err}\")\n",
    "        raise err\n",
    "\n",
    "    # 모델 다운로드 URL 및 파일명 추출\n",
    "    download_url = response.json()[\"modelVersions\"][0][\"downloadUrl\"]\n",
    "    filename = response.json()[\"modelVersions\"][0][\"files\"][0][\"name\"]\n",
    "\n",
    "    file_path = f\"models/{filename}\"\n",
    "\n",
    "    # 이미 다운로드된 파일이 존재하는 경우\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[INFO] File already exists: {file_path}\")\n",
    "        return file_path\n",
    "\n",
    "    # 모델 저장 디렉토리 생성\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    # 모델 다운로드\n",
    "    download_from_url(download_url, file_path)\n",
    "    print(f\"[INFO] File downloaded: {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# URL로부터 파일 다운로드 함수\n",
    "def download_from_url(url: str, file_path: str, chunk_size=1024):\n",
    "    try:\n",
    "        resp = requests.get(url, stream=True)\n",
    "        resp.raise_for_status()  # 다운로드 요청 상태 확인\n",
    "    except Exception as err:\n",
    "        print(f\"[ERROR] {err}\")\n",
    "        raise err\n",
    "\n",
    "    total = int(resp.headers.get('content-length', 0))  # 파일 크기 추출\n",
    "    with open(file_path, 'wb') as file, tqdm(\n",
    "        desc=file_path,\n",
    "        total=total,\n",
    "        unit='iB',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in resp.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "\n",
    "# 모델 파이프라인 초기화 함수\n",
    "def init_pipeline() -> str:\n",
    "    global MODEL_PATH  # 전역 변수를 사용\n",
    "\n",
    "    if MODEL_PATH is None:\n",
    "        # MODEL_PATH가 없으면 ./models에서 모델을 찾음\n",
    "        print(\"[INFO] No model path found, searching ./models directory...\")\n",
    "        MODEL_PATH = find_latest_model_in_directory(\"./models\")\n",
    "\n",
    "    if MODEL_PATH is None:\n",
    "        return \"Error: No model found in ./models directory\"\n",
    "\n",
    "    print(f\"[INFO] Initialize pipeline with model: {MODEL_PATH}\")\n",
    "    global PIPELINE\n",
    "\n",
    "    try:\n",
    "        PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
    "            MODEL_PATH,\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True,\n",
    "        ).to(\"cuda\")\n",
    "        print(\"[INFO] Initialized pipeline\")\n",
    "        return \"Model Loaded!\"\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load model: {e}\")\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# 결과 이미지를 저장할 디렉토리 생성 함수\n",
    "def save_image(image: Image.Image, filename: str):\n",
    "    # 'result' 디렉토리가 없으면 생성\n",
    "    os.makedirs('result', exist_ok=True)\n",
    "\n",
    "    # 파일 경로 생성\n",
    "    file_path = os.path.join('result', filename)\n",
    "\n",
    "    # 이미지 저장\n",
    "    image.save(file_path, format='JPEG')\n",
    "    print(f\"[INFO] Image saved at {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# 스케치에서 이미지를 생성하는 함수 수정\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "def sketch_to_image(sketch: Image.Image, prompt: List[str], negative_prompt: List[str]):\n",
    "    global PIPELINE\n",
    "    if PIPELINE is None:\n",
    "        return \"[ERROR] Pipeline is not initialized.\"\n",
    "\n",
    "    # 프롬프트와 네거티브 프롬프트를 리스트로 변환\n",
    "    if isinstance(prompt, str):\n",
    "        prompt = [prompt]\n",
    "    if isinstance(negative_prompt, str):\n",
    "        negative_prompt = [negative_prompt]\n",
    "\n",
    "    # 프롬프트와 네거티브 프롬프트 개수 일치\n",
    "    if len(prompt) != len(negative_prompt):\n",
    "        if len(prompt) > len(negative_prompt):\n",
    "            negative_prompt += [\"\"] * (len(prompt) - len(negative_prompt))\n",
    "        else:\n",
    "            prompt += [\"\"] * (len(negative_prompt) - len(prompt))\n",
    "\n",
    "    width, height = sketch.size\n",
    "    images = [sketch] * len(prompt)\n",
    "\n",
    "    try:\n",
    "        # 이미지 생성\n",
    "        result = PIPELINE(\n",
    "            image=images,\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            num_images_per_prompt=2,\n",
    "            num_inference_steps=20,\n",
    "            strength=0.7,\n",
    "        ).images\n",
    "\n",
    "        # 첫 번째 이미지를 저장\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        filename = f\"generated_image_{timestamp}.jpg\"\n",
    "        save_image(result[0], filename)\n",
    "\n",
    "        return result[0]\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to generate image: {e}\")\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405,
     "referenced_widgets": [
      "7d23c546856046b8a04d4b273cd4b937",
      "0eaa7ef58af04778bfb5f54eaabfb8ba",
      "8271ddf6705c44d3a96ab1e2d687f545",
      "df34772ab0c34a2eb37deefb9f54c4bd",
      "37a6e0089d784c1a90932334a3e14c19",
      "a7aabe5d0024494f9595460a8f9eb6d7",
      "01c5c959f43e446a9221b6865d695296",
      "7b41218fe7f34bc6a1ee1d5ff97cfc1b",
      "3c69b99081584fa7a147edc43ac75a7b",
      "eb51b26acfca4e1a9419edfed63d10fd",
      "114850b2cb5c4b4a89ffd60464961ee3"
     ]
    },
    "id": "QcAEk-3kcnEN",
    "outputId": "67bca309-216b-4aaa-c376-c32a33f4a65e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Gradio app ready\n",
      "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://e94f615962dc3064ae.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "[INFO] No model path found, searching ./models directory...\n",
      "[INFO] Initialize pipeline with model: ./models/disneyPixarCartoon_v10.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initialized pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py:704: FutureWarning: You have passed 2 text prompts (`prompt`), but only 1 initial images (`image`). Initial images are now duplicating to match the number of text prompts. Note that this behavior is deprecated and will be removed in a version 1.0.0. Please make sure to update your script to pass as many initial images as text prompts to suppress this warning.\n",
      "  deprecate(\"len(prompt) != len(image)\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d23c546856046b8a04d4b273cd4b937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Image saved at result/generated_image_20240925-081214.jpg\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://e94f615962dc3064ae.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[INFO] Gradio app ready\")\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# 스케치 to 이미지 애플리케이션\")\n",
    "\n",
    "    # 모델 다운로드 섹션\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label=\"Model Link\", placeholder=\"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value=\"Download model\")\n",
    "    with gr.Row():\n",
    "        download_status = gr.Textbox(label=\"Download Status\", value=\"Not downloaded yet\")\n",
    "\n",
    "    # 모델 불러오기 섹션\n",
    "    gr.Markdown(\"## 모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        load_model_btn = gr.Button(value=\"Load model\")\n",
    "    with gr.Row():\n",
    "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not loaded\")\n",
    "\n",
    "    # 프롬프트 입력 섹션\n",
    "    gr.Markdown(\"## 프롬프트 입력\")\n",
    "    with gr.Row():\n",
    "        prompt = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Row():\n",
    "        n_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
    "\n",
    "    # 스케치 to 이미지 생성 섹션\n",
    "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Tab(\"Canvas\"):\n",
    "                with gr.Row():\n",
    "                    canvas = gr.Image(\n",
    "                        label=\"Draw\",\n",
    "                        source=\"canvas\",\n",
    "                        image_mode=\"RGB\",\n",
    "                        tool=\"color-sketch\",\n",
    "                        interactive=True,\n",
    "                        width=WIDTH,\n",
    "                        height=HEIGHT,\n",
    "                        shape=(WIDTH, HEIGHT),\n",
    "                        brush_radius=20,\n",
    "                        type=\"pil\",\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    canvas_run_btn = gr.Button(value=\"Generate from Canvas\")\n",
    "\n",
    "            with gr.Tab(\"File\"):\n",
    "                with gr.Row():\n",
    "                    file = gr.Image(\n",
    "                        label=\"Upload\",\n",
    "                        source=\"upload\",\n",
    "                        image_mode=\"RGB\",\n",
    "                        interactive=True,\n",
    "                        width=WIDTH,\n",
    "                        height=HEIGHT,\n",
    "                        type=\"pil\",\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    file_run_btn = gr.Button(value=\"Generate from File\")\n",
    "\n",
    "        # 결과 이미지 갤러리\n",
    "        with gr.Column():\n",
    "            result_image = gr.Image(label=\"Output Image\", type=\"pil\")\n",
    "\n",
    "    # Event 핸들러 설정\n",
    "    # 모델 다운로드 버튼 클릭 이벤트\n",
    "    download_model_btn.click(\n",
    "        download_model,  # 모델 다운로드 함수 호출\n",
    "        [model_url],  # 입력으로 model_url 사용\n",
    "        [download_status],  # 다운로드 상태를 download_status 텍스트박스에 표시\n",
    "    )\n",
    "\n",
    "    # 모델 불러오기 버튼 클릭 이벤트\n",
    "    load_model_btn.click(\n",
    "        init_pipeline,  # 모델 로드 함수 호출\n",
    "        [],  # 파일 경로는 함수 내에서 관리하므로 입력 없음\n",
    "        [is_model_check],  # 모델 로드 상태를 is_model_check 텍스트박스에 표시\n",
    "    )\n",
    "\n",
    "    # Canvas에서 이미지 생성 버튼 클릭 이벤트\n",
    "    canvas_run_btn.click(\n",
    "        sketch_to_image,  # 스케치에서 이미지 생성 함수 호출\n",
    "        [canvas, prompt, n_prompt],  # 입력으로 canvas, prompt, negative prompt 사용\n",
    "        [result_image],  # 출력 이미지가 result_gallery에 표시\n",
    "    )\n",
    "\n",
    "    # File 업로드에서 이미지 생성 버튼 클릭 이벤트\n",
    "    file_run_btn.click(\n",
    "        sketch_to_image,  # 업로드된 이미지에서 생성 함수 호출\n",
    "        [file, prompt, n_prompt],  # 입력으로 업로드된 파일, prompt, negative prompt 사용\n",
    "        [result_image],  # 출력 이미지가 result_gallery에 표시\n",
    "    )\n",
    "\n",
    "# Gradio 애플리케이션 실행\n",
    "app.queue().launch(inline=False, share=True, debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYqUda4T1LdK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SM1HqDzu2KuF",
    "outputId": "e60bd6a6-69f3-45e8-ffc3-37ec0db596c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uf9TcRItMH1l"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01c5c959f43e446a9221b6865d695296": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eaa7ef58af04778bfb5f54eaabfb8ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7aabe5d0024494f9595460a8f9eb6d7",
      "placeholder": "​",
      "style": "IPY_MODEL_01c5c959f43e446a9221b6865d695296",
      "value": "100%"
     }
    },
    "114850b2cb5c4b4a89ffd60464961ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37a6e0089d784c1a90932334a3e14c19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c69b99081584fa7a147edc43ac75a7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b41218fe7f34bc6a1ee1d5ff97cfc1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d23c546856046b8a04d4b273cd4b937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0eaa7ef58af04778bfb5f54eaabfb8ba",
       "IPY_MODEL_8271ddf6705c44d3a96ab1e2d687f545",
       "IPY_MODEL_df34772ab0c34a2eb37deefb9f54c4bd"
      ],
      "layout": "IPY_MODEL_37a6e0089d784c1a90932334a3e14c19"
     }
    },
    "8271ddf6705c44d3a96ab1e2d687f545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b41218fe7f34bc6a1ee1d5ff97cfc1b",
      "max": 14,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c69b99081584fa7a147edc43ac75a7b",
      "value": 14
     }
    },
    "a7aabe5d0024494f9595460a8f9eb6d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df34772ab0c34a2eb37deefb9f54c4bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb51b26acfca4e1a9419edfed63d10fd",
      "placeholder": "​",
      "style": "IPY_MODEL_114850b2cb5c4b4a89ffd60464961ee3",
      "value": " 14/14 [00:04&lt;00:00,  2.89it/s]"
     }
    },
    "eb51b26acfca4e1a9419edfed63d10fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
