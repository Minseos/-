{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0de0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b789a60b",
   "metadata": {},
   "source": [
    "# 뱅뱅막국수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ec1136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/뱅뱅막국수_combined_reviews_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 분석할 파일 경로\n",
    "review_file_path = \"./data/합본/뱅뱅막국수_combined_reviews.csv\"\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다. 문맥이 없는 단어(예: '좋아요', '별로예요')만 있는 경우, 단어의 감성에 따라 '긍정적' 또는 '부정적'으로 응답하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '긍정적' 또는 '부정적' 형식으로만 응답해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=10,  # 응답 길이를 줄입니다.\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        response_text = response.choices[0].message['content'].strip()\n",
    "        if \"긍정적\" in response_text:\n",
    "            sentiment = \"긍정적\"\n",
    "        elif \"부정적\" in response_text:\n",
    "            sentiment = \"부정적\"\n",
    "        else:\n",
    "            sentiment = \"알 수 없음\"\n",
    "        \n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "output_path = \"./data/뱅뱅막국수_combined_reviews_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(f\"감성 분석 완료 및 결과 저장: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15358f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Using cached transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "Downloading torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 10.0/203.1 MB 47.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 29.4/203.1 MB 69.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 37.7/203.1 MB 61.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 48.2/203.1 MB 62.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 61.9/203.1 MB 60.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 62.4/203.1 MB 50.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 74.4/203.1 MB 51.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 87.8/203.1 MB 52.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 104.3/203.1 MB 56.0 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 123.7/203.1 MB 59.8 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 132.6/203.1 MB 58.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 150.7/203.1 MB 60.6 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 155.2/203.1 MB 61.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 169.1/203.1 MB 58.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 187.7/203.1 MB 60.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 62.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 62.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 62.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.1/203.1 MB 53.4 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 68.4 MB/s eta 0:00:00\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 91.3 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, networkx, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.2 mpmath-1.3.0 networkx-3.4.2 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.20.3 torch-2.5.1 transformers-4.46.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fdfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175528b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b998d2dc",
   "metadata": {},
   "source": [
    "# 파스쿠찌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cfa77a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/분석/파스쿠찌_combined_reviews_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 분석할 파일 경로\n",
    "review_file_path = \"./data/합본/파스쿠찌_combined_reviews.csv\"\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다. 문맥이 없는 단어(예: '좋아요', '별로예요')만 있는 경우, 단어의 감성에 따라 '긍정적' 또는 '부정적'으로 응답하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '긍정적' 또는 '부정적' 형식으로만 응답해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=10,  # 응답 길이를 줄입니다.\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        response_text = response.choices[0].message['content'].strip()\n",
    "        if \"긍정적\" in response_text:\n",
    "            sentiment = \"긍정적\"\n",
    "        elif \"부정적\" in response_text:\n",
    "            sentiment = \"부정적\"\n",
    "        else:\n",
    "            sentiment = \"알 수 없음\"\n",
    "        \n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "output_path = \"./data/분석/파스쿠찌_combined_reviews_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(f\"감성 분석 완료 및 결과 저장: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c104f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c058232a",
   "metadata": {},
   "source": [
    "# 한강수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28200414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/분석/한강수_combined_reviews_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 분석할 파일 경로\n",
    "review_file_path = \"./data/합본/한강수_combined_reviews.csv\"\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다. 문맥이 없는 단어(예: '좋아요', '별로예요')만 있는 경우, 단어의 감성에 따라 '긍정적' 또는 '부정적'으로 응답하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '긍정적' 또는 '부정적' 형식으로만 응답해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=10,  # 응답 길이를 줄입니다.\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        response_text = response.choices[0].message['content'].strip()\n",
    "        if \"긍정적\" in response_text:\n",
    "            sentiment = \"긍정적\"\n",
    "        elif \"부정적\" in response_text:\n",
    "            sentiment = \"부정적\"\n",
    "        else:\n",
    "            sentiment = \"알 수 없음\"\n",
    "        \n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "output_path = \"./data/분석/한강수_combined_reviews_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(f\"감성 분석 완료 및 결과 저장: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94087796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b14bf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
