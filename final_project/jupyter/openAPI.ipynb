{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d191c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai  # openai 모듈을 전체로 import합니다\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a993820",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 윈도우 환경변수에 등록했던 OPENAI_API_KEY를 불러와 사용\u001b[39;00m\n\u001b[0;32m      4\u001b[0m client\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "# 윈도우 환경변수에 등록했던 OPENAI_API_KEY를 불러와 사용\n",
    "client.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Python에 대해 알려주세요\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41deb1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e46d411",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (C:\\Users\\5-04\\miniforge3\\envs\\openai\\Lib\\site-packages\\openai\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m      5\u001b[0m client\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (C:\\Users\\5-04\\miniforge3\\envs\\openai\\Lib\\site-packages\\openai\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# GPT API를 통해 요청 보내고 결과 가져오는 부분\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Python에 대해 알려주세요\"},\n",
    "    ],\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b376f0",
   "metadata": {},
   "source": [
    "다른 정보 없이 답변만 출력하고 싶다면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa64c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python은 객체지향적 프로그래밍 언어로, 귀도 반 로섬(Guido van Rossum)에 의해 1991년에 발표되었습니다. Python은 간결하고 가독성이 높은 문법을 가지고 있어 입문자에게 쉽게 접근할 수 있는 언어입니다. 또한 동적 타입 지정, 자동 메모리 관리 등의 기능을 제공하여 개발자가 더욱 효율적으로 코드를 작성할 수 있도록 도와줍니다.\n",
      "\n",
      "Python은 다양한 운영 체제에서 사용할 수 있으며, 다양한 응용 분야에서 널리 사용되고 있습니다. 데이터 분석, 인공지능, 웹 개발, 시스템 관리 등 다양한 분야에서 Python은 많은 사용자들에게 선호되는 언어입니다.\n",
      "\n",
      "또한 Python은 방대한 수의 라이브러리와 프레임워크를 제공하여 개발자들이 더욱 쉽고 빠르게 프로젝트를 개발할 수 있도록 도와줍니다. 대표적인 라이브러리로는 NumPy, Pandas, Matplotlib, TensorFlow 등이 있습니다.\n",
      "\n",
      "Python은 무료로 사용할 수 있고 커뮤니티가 크기 때문에 많은 도움을 받을 수 있습니다. 따라서 많은 개발자들이 Python을 선호하고, 다양한 프로젝트와 채용에서도 Python 경험을 요구하는 경우가 많습니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c9966",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e288723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국에서 주목받는 핀테크 기업 중 일부는 다음과 같습니다. \n",
      "\n",
      "1. Stripe: 온라인 결제 및 금융 인프라 서비스를 제공하는 기업으로, 전 세계적으로 인기 있는 결제 플랫폼을 운영하고 있습니다.\n",
      "2. Robinhood: 주식 및 암호화폐 거래 플랫폼으로, 수수료 없는 거래를 제공하여 투자를 보다 접근 가능하게 만들고 있습니다.\n",
      "3. Square: 온라인 및 오프라인 결제 서비스를 제공하는 기업으로, 중소기업을 위한 간편한 결제 솔루션을 제공하고 있습니다.\n",
      "4. SoFi: 학자금 대출, 개인 대출, 투자 등 다양한 금융 서비스를 제공하는 핀테크 기업으로, 디지털 금융 서비스를 중심으로 사업을 확장하고 있습니다.\n",
      "5. Chime: 온라인 전용 은행으로, 수수료 없는 은행 서비스와 디지털 금융 서비스를 제공하고 있습니다.\n",
      "6. Plaid: 금융 데이터 API를 제공하는 기업으로, 은행과 소비자 간의 연결을 강화하고 다양한 금융 애플리케이션을 지원하고 있습니다.\n",
      "7. Affirm: 할부 결제 서비스를 제공하는 기업으로, 소비자들에게 구매력을 높이는 서비스를 제공하고 있습니다.\n",
      "8. Brex: 기업용 신용카드 및 금융 서비스를 제공하는 기업으로, 스타트업 및 중소기업을 위한 혁신적인 금융 솔루션을 제공하고 있습니다.\n",
      "9. Betterment: 자동 투자 서비스를 제공하는 로보어드바이저 기업으로, 투자 포트폴리오를 최적화하여 고객의 투자 수익을 극대화하고 있습니다.\n",
      "10. Lemonade: 디지털 보험 서비스를 제공하는 기업으로, 인공지능을 활용한 보험 청구 및 가입 프로세스를 제공하고 있습니다.\n",
      "\n",
      "각 기업은 고객들에게 혁신적이고 편리한 금융 서비스를 제공하여 주목받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# GPT API를 통해 요청 보내고 결과 가져오는 부분\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # 또는 \"gpt-4\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"핀테크 전문가로서 대답해 줘\"},\n",
    "        {\"role\": \"user\", \"content\": \"미국에서 가장 주목받는 핀테크 기업 목록 10개를 알려주고 주요 서비스에 대해서 알려주세요.\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 응답 내용 출력\n",
    "print(response.choices[0].message[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e9a5e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (C:\\Users\\5-04\\miniforge3\\envs\\openai\\Lib\\site-packages\\openai\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m      5\u001b[0m client\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (C:\\Users\\5-04\\miniforge3\\envs\\openai\\Lib\\site-packages\\openai\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# GPT API를 통해 요청 보내고 결과 가져오는 부분\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"핀테크 전문가로서 대답해 줘\",\n",
    "         \"role\": \"user\", \"content\": \"미국에서 가장 주목받는 핀테크 기업목록 \\\n",
    "                                     10개를 알려주고 주요 서비스에 대해서 알려주세요.\"\n",
    "        },\n",
    "    ],\n",
    "    temperature = 0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69b211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fa834f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'review_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'review_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 리뷰마다 OpenAI API를 통해 감성 분석 요청\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review_text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mreviews_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# GPT 모델에 감성 분석 요청\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     20\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# 또는 \"gpt-4\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m             messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m             temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     26\u001b[0m         )\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'review_text'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# 리뷰 데이터 불러오기\n",
    "review_file_path = \"./data/뱅뱅막국수_reviews_추천순.csv\"  # 결합된 리뷰 파일 경로\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 OpenAI API를 통해 감성 분석 요청\n",
    "for review_text in reviews_df['Review']:\n",
    "    try:\n",
    "        # GPT 모델에 감성 분석 요청\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # 또는 \"gpt-4\"\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"너는 감성 분석 전문가로서, 주어진 리뷰의 감성을 분석해줘.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성 분석을 해주세요: '{review_text}'\"},\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        sentiment = response.choices[0].message['content']\n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review: {e}\")\n",
    "        sentiments.append(\"Error\")  # 오류 시 \"Error\"로 표시\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 분석 결과 저장\n",
    "output_path = \"./data/reviews_with_sentiments.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"감성 분석 완료 및 결과 저장:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99116923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from openai==0.28) (4.67.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from openai==0.28) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from aiohttp->openai==0.28) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\5-04\\miniforge3\\envs\\openai\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.0\n",
      "    Uninstalling openai-0.27.0:\n",
      "      Successfully uninstalled openai-0.27.0\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323f421",
   "metadata": {},
   "source": [
    "# 시간이 좀 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b900aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review_text \u001b[38;5;129;01min\u001b[39;00m reviews_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]:  \u001b[38;5;66;03m# Assuming the column name is 'Review'\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# Use the latest ChatCompletion model for sentiment analysis\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-1106\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Updated model name\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant specialized in sentiment analysis.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlease analyze the sentiment of the following review: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mreview_text\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m. Is this review positive, negative, or neutral?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;66;03m# Extract sentiment analysis result from the API response\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         sentiment \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\openai\\api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\openai\\api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    594\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession_create_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\http\\client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\openai\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Load review data\n",
    "review_file_path = \"./data/뱅뱅막국수_reviews_추천순.csv\"\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# List to store sentiment analysis results\n",
    "sentiments = []\n",
    "\n",
    "# Perform sentiment analysis for each review\n",
    "for review_text in reviews_df['Review']:  # Assuming the column name is 'Review'\n",
    "    try:\n",
    "        # Use the latest ChatCompletion model for sentiment analysis\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",  # Updated model name\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in sentiment analysis.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Please analyze the sentiment of the following review: '{review_text}'. Is this review positive, negative, or neutral?\"}\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # Extract sentiment analysis result from the API response\n",
    "        sentiment = response.choices[0].message['content'].strip()\n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review: {e}\")\n",
    "        sentiments.append(\"Error\")\n",
    "        time.sleep(1)  # Pause briefly if an error occurs\n",
    "    \n",
    "    # Control request frequency\n",
    "    time.sleep(0.5)  # Add a delay between requests\n",
    "\n",
    "# Add results to the DataFrame\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# Save the analysis results\n",
    "output_path = \"./data/reviews_with_sentiments.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"Sentiment analysis completed and results saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de56fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "399e59e2",
   "metadata": {},
   "source": [
    "# 뱅뱅막국수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0eff1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/뱅뱅막국수_reviews_추천순_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 리뷰 데이터 불러오기\n",
    "review_file_path = \"./data/뱅뱅막국수_reviews_추천순.csv\"\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '이 리뷰는 긍정적', '이 리뷰는 부정적', 또는 '이 리뷰는 중립적' 형식으로만 응답해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        sentiment = response.choices[0].message['content'].strip()\n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "base_name = os.path.splitext(os.path.basename(review_file_path))[0]\n",
    "output_path = f\"./data/{base_name}_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"감성 분석 완료 및 결과 저장:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce483e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5045635",
   "metadata": {},
   "source": [
    "# 24하이들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1a25b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/24시 하이들_reviews_추천순_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 리뷰 데이터 불러오기\n",
    "review_file_path = \"./data/뱅뱅막국수_reviews_추천순.csv\"\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '이 리뷰는 긍정적', '이 리뷰는 부정적', 또는 '이 리뷰는 중립적' 형식으로만 응답해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        sentiment = response.choices[0].message['content'].strip()\n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "base_name = os.path.splitext(os.path.basename(review_file_path))[0]\n",
    "output_path = f\"./data/{base_name}_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"감성 분석 완료 및 결과 저장:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ccdbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009eb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8294710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/24시 하이들_reviews_추천순_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 리뷰 데이터 불러오기\n",
    "review_file_path = \"./data/24시 하이들_reviews_추천순.csv\"\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다. 문맥이 없는 단어(예: '좋아요', '별로예요')만 있는 경우, 단어의 감성에 따라 '긍정적' 또는 '부정적'으로 응답하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '이 리뷰는 긍정적', '이 리뷰는 부정적', 또는 '이 리뷰는 중립적' 형식으로만 응답해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=20,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        sentiment = response.choices[0].message['content'].strip()\n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "base_name = os.path.splitext(os.path.basename(review_file_path))[0]\n",
    "output_path = f\"./data/{base_name}_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"감성 분석 완료 및 결과 저장:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54982e",
   "metadata": {},
   "source": [
    "# 한강수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa71c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/한강수_reviews_추천순_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 리뷰 데이터 불러오기\n",
    "review_file_path = \"./data/한강수_reviews_추천순.csv\"\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다. 문맥이 없는 단어(예: '좋아요', '별로예요')만 있는 경우, 단어의 감성에 따라 '긍정적' 또는 '부정적'으로 응답하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '이 리뷰는 긍정적', '이 리뷰는 부정적', 또는 '이 리뷰는 중립적' 형식으로만 응답해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=20,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        sentiment = response.choices[0].message['content'].strip()\n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "base_name = os.path.splitext(os.path.basename(review_file_path))[0]\n",
    "output_path = f\"./data/{base_name}_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"감성 분석 완료 및 결과 저장:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be6c61",
   "metadata": {},
   "source": [
    "# 파스쿠찌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15775c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/파스쿠찌_뱅뱅사거리점_reviews_추천순_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 리뷰 데이터 불러오기\n",
    "review_file_path = \"./data/파스쿠찌_뱅뱅사거리점_reviews_추천순.csv\"\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다. 문맥이 없는 단어(예: '좋아요', '별로예요')만 있는 경우, 단어의 감성에 따라 '긍정적' 또는 '부정적'으로 응답하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '이 리뷰는 긍정적', '이 리뷰는 부정적 형식으로만 응답해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과 추출\n",
    "        sentiment = response.choices[0].message['content'].strip()\n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "base_name = os.path.splitext(os.path.basename(review_file_path))[0]\n",
    "output_path = f\"./data/{base_name}_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"감성 분석 완료 및 결과 저장:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d624d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0c154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa2dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de3c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/한강수_reviews_추천순_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 리뷰 데이터 불러오기\n",
    "review_file_path = \"./data/한강수_reviews_추천순.csv\"\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "criteria = []  # 기준 설명을 저장할 리스트\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다. 문맥이 없는 단어(예: '좋아요', '별로예요')만 있는 경우, 단어의 감성에 따라 '긍정적' 또는 '부정적'으로 응답하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '이 리뷰는 긍정적', '이 리뷰는 부정적' 형식으로만 응답하고, 각 판단의 이유를 간단히 설명해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=50,  # 설명을 포함할 수 있도록 토큰 수를 늘립니다.\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과와 기준 설명 추출\n",
    "        sentiment = response.choices[0].message['content'].strip().split(\"\\n\")[0]  # 첫 줄의 결과만 가져옴\n",
    "        explanation = response.choices[0].message['content'].strip().split(\"\\n\")[1] if len(response.choices[0].message['content'].strip().split(\"\\n\")) > 1 else \"기준 설명 없음\"\n",
    "        \n",
    "        sentiments.append(sentiment)\n",
    "        criteria.append(explanation)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        criteria.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "reviews_df['criteria'] = criteria  # 기준 설명 컬럼 추가\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "base_name = os.path.splitext(os.path.basename(review_file_path))[0]\n",
    "output_path = f\"./data/{base_name}_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"감성 분석 완료 및 결과 저장:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f1400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23f04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "113a9149",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c27d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 완료 및 결과 저장: ./data/파스쿠찌_뱅뱅사거리점_reviews_추천순_분석.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 리뷰 데이터 불러오기\n",
    "review_file_path = \"./data/파스쿠찌_뱅뱅사거리점_reviews_추천순.csv\"\n",
    "reviews_df = pd.read_csv(review_file_path)\n",
    "\n",
    "# 감성 분석 결과를 저장할 리스트\n",
    "sentiments = []\n",
    "criteria = []  # 기준 설명을 저장할 리스트\n",
    "\n",
    "# 리뷰마다 감성 분석 수행\n",
    "for review_text in reviews_df['Review']:  # 컬럼명이 'Review'라고 가정\n",
    "    try:\n",
    "        # 최신 ChatCompletion 모델을 사용한 감성 분석\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 감성 분석을 전문으로 하는 도움말 어시스턴트입니다. 문맥이 없는 단어(예: '좋아요', '별로예요')만 있는 경우, 단어의 감성에 따라 '긍정적' 또는 '부정적'으로 응답하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"다음 리뷰의 감성을 분석하여 '긍정적' 또는 '부정적' 형식으로만 응답하고, 각 판단의 이유를 간단히 설명해 주세요: '{review_text}'\"}\n",
    "            ],\n",
    "            max_tokens=200,  # 설명을 포함할 수 있도록 토큰 수를 늘립니다.\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # API 응답에서 감성 분석 결과와 기준 설명 추출\n",
    "        response_text = response.choices[0].message['content'].strip()\n",
    "        if \"긍정적\" in response_text:\n",
    "            sentiment = \"긍정적\"\n",
    "        elif \"부정적\" in response_text:\n",
    "            sentiment = \"부정적\"\n",
    "        else:\n",
    "            sentiment = \"알 수 없음\"\n",
    "        \n",
    "        # 기준 설명 추출 (있을 경우)\n",
    "        criteria_line = response_text.split(\"\\n\")[1] if len(response_text.split(\"\\n\")) > 1 else \"기준 설명 없음\"  # 두 번째 줄에 설명 추출\n",
    "        \n",
    "        sentiments.append(sentiment)\n",
    "        criteria.append(criteria_line)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "        sentiments.append(\"오류\")\n",
    "        criteria.append(\"오류\")\n",
    "        time.sleep(1)  # 오류 발생 시 잠시 대기\n",
    "    \n",
    "    # 요청 빈도 제어\n",
    "    time.sleep(0.5)  # 각 요청 사이에 대기 시간 추가\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "reviews_df['sentiment'] = sentiments\n",
    "reviews_df['criteria'] = criteria  # 기준 설명 컬럼 추가\n",
    "\n",
    "# 원본 파일 이름에 \"_분석\" 추가하여 저장\n",
    "base_name = os.path.splitext(os.path.basename(review_file_path))[0]\n",
    "output_path = f\"./data/{base_name}_분석.csv\"\n",
    "reviews_df.to_csv(output_path, index=False)\n",
    "print(\"감성 분석 완료 및 결과 저장:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e330288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
