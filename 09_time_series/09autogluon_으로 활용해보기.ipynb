{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882e26ea-9e70-4c7a-a19d-a069cc0cfbe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting koreanize_matplotlib\n",
      "  Using cached koreanize_matplotlib-0.1.1-py3-none-any.whl.metadata (992 bytes)\n",
      "Requirement already satisfied: matplotlib in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from koreanize_matplotlib) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/miniforge3/envs/ag/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->koreanize_matplotlib) (1.16.0)\n",
      "Using cached koreanize_matplotlib-0.1.1-py3-none-any.whl (7.9 MB)\n",
      "Installing collected packages: koreanize_matplotlib\n",
      "Successfully installed koreanize_matplotlib-0.1.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install autogluon\n",
    "# !pip install seaborn\n",
    "!pip install koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec191bb3-be07-4ec8-a050-aa6f96f0e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33858392-8236-49fd-bd1c-5c772f00cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/tr_eod_data_rounded.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4105ed32-7cfe-428e-99fe-d2aca6505f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL.O</th>\n",
       "      <th>MSFT.O</th>\n",
       "      <th>INTC.O</th>\n",
       "      <th>AMZN.O</th>\n",
       "      <th>GS.N</th>\n",
       "      <th>SPY</th>\n",
       "      <th>.SPX</th>\n",
       "      <th>.VIX</th>\n",
       "      <th>EUR=</th>\n",
       "      <th>XAU=</th>\n",
       "      <th>GDX</th>\n",
       "      <th>GLD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1096.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>30.57</td>\n",
       "      <td>30.95</td>\n",
       "      <td>20.88</td>\n",
       "      <td>133.90</td>\n",
       "      <td>173.08</td>\n",
       "      <td>113.33</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>20.04</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1120.00</td>\n",
       "      <td>47.71</td>\n",
       "      <td>109.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>30.63</td>\n",
       "      <td>30.96</td>\n",
       "      <td>20.87</td>\n",
       "      <td>134.69</td>\n",
       "      <td>176.14</td>\n",
       "      <td>113.63</td>\n",
       "      <td>1136.52</td>\n",
       "      <td>19.35</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1118.65</td>\n",
       "      <td>48.17</td>\n",
       "      <td>109.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>30.14</td>\n",
       "      <td>30.77</td>\n",
       "      <td>20.80</td>\n",
       "      <td>132.25</td>\n",
       "      <td>174.26</td>\n",
       "      <td>113.71</td>\n",
       "      <td>1137.14</td>\n",
       "      <td>19.16</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1138.50</td>\n",
       "      <td>49.34</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>30.08</td>\n",
       "      <td>30.45</td>\n",
       "      <td>20.60</td>\n",
       "      <td>130.00</td>\n",
       "      <td>177.67</td>\n",
       "      <td>114.19</td>\n",
       "      <td>1141.69</td>\n",
       "      <td>19.06</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1131.90</td>\n",
       "      <td>49.10</td>\n",
       "      <td>110.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25</th>\n",
       "      <td>182.17</td>\n",
       "      <td>98.39</td>\n",
       "      <td>50.71</td>\n",
       "      <td>1663.15</td>\n",
       "      <td>221.54</td>\n",
       "      <td>271.00</td>\n",
       "      <td>2717.07</td>\n",
       "      <td>17.33</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1265.00</td>\n",
       "      <td>22.01</td>\n",
       "      <td>119.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26</th>\n",
       "      <td>184.43</td>\n",
       "      <td>99.08</td>\n",
       "      <td>49.67</td>\n",
       "      <td>1691.09</td>\n",
       "      <td>221.58</td>\n",
       "      <td>271.60</td>\n",
       "      <td>2723.06</td>\n",
       "      <td>15.92</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1258.64</td>\n",
       "      <td>21.95</td>\n",
       "      <td>119.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-27</th>\n",
       "      <td>184.16</td>\n",
       "      <td>97.54</td>\n",
       "      <td>48.76</td>\n",
       "      <td>1660.51</td>\n",
       "      <td>220.18</td>\n",
       "      <td>269.35</td>\n",
       "      <td>2699.63</td>\n",
       "      <td>17.91</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1251.62</td>\n",
       "      <td>21.81</td>\n",
       "      <td>118.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>185.50</td>\n",
       "      <td>98.63</td>\n",
       "      <td>49.25</td>\n",
       "      <td>1701.45</td>\n",
       "      <td>223.42</td>\n",
       "      <td>270.89</td>\n",
       "      <td>2716.31</td>\n",
       "      <td>16.85</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1247.88</td>\n",
       "      <td>21.93</td>\n",
       "      <td>118.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>185.11</td>\n",
       "      <td>98.61</td>\n",
       "      <td>49.71</td>\n",
       "      <td>1699.80</td>\n",
       "      <td>220.57</td>\n",
       "      <td>271.28</td>\n",
       "      <td>2718.37</td>\n",
       "      <td>16.09</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1252.25</td>\n",
       "      <td>22.31</td>\n",
       "      <td>118.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2216 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL.O  MSFT.O  INTC.O   AMZN.O    GS.N     SPY     .SPX   .VIX  \\\n",
       "Date                                                                          \n",
       "2010-01-01     NaN     NaN     NaN      NaN     NaN     NaN      NaN    NaN   \n",
       "2010-01-04   30.57   30.95   20.88   133.90  173.08  113.33  1132.99  20.04   \n",
       "2010-01-05   30.63   30.96   20.87   134.69  176.14  113.63  1136.52  19.35   \n",
       "2010-01-06   30.14   30.77   20.80   132.25  174.26  113.71  1137.14  19.16   \n",
       "2010-01-07   30.08   30.45   20.60   130.00  177.67  114.19  1141.69  19.06   \n",
       "...            ...     ...     ...      ...     ...     ...      ...    ...   \n",
       "2018-06-25  182.17   98.39   50.71  1663.15  221.54  271.00  2717.07  17.33   \n",
       "2018-06-26  184.43   99.08   49.67  1691.09  221.58  271.60  2723.06  15.92   \n",
       "2018-06-27  184.16   97.54   48.76  1660.51  220.18  269.35  2699.63  17.91   \n",
       "2018-06-28  185.50   98.63   49.25  1701.45  223.42  270.89  2716.31  16.85   \n",
       "2018-06-29  185.11   98.61   49.71  1699.80  220.57  271.28  2718.37  16.09   \n",
       "\n",
       "            EUR=     XAU=    GDX     GLD  \n",
       "Date                                      \n",
       "2010-01-01  1.43  1096.35    NaN     NaN  \n",
       "2010-01-04  1.44  1120.00  47.71  109.80  \n",
       "2010-01-05  1.44  1118.65  48.17  109.70  \n",
       "2010-01-06  1.44  1138.50  49.34  111.51  \n",
       "2010-01-07  1.43  1131.90  49.10  110.82  \n",
       "...          ...      ...    ...     ...  \n",
       "2018-06-25  1.17  1265.00  22.01  119.89  \n",
       "2018-06-26  1.16  1258.64  21.95  119.26  \n",
       "2018-06-27  1.16  1251.62  21.81  118.58  \n",
       "2018-06-28  1.16  1247.88  21.93  118.22  \n",
       "2018-06-29  1.17  1252.25  22.31  118.65  \n",
       "\n",
       "[2216 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a53781-9f4d-442f-b7ea-6274bd2c1796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL.O    78\n",
       "MSFT.O    78\n",
       "INTC.O    78\n",
       "AMZN.O    78\n",
       "GS.N      78\n",
       "SPY       78\n",
       ".SPX      78\n",
       ".VIX      78\n",
       "EUR=       0\n",
       "XAU=       5\n",
       "GDX       78\n",
       "GLD       78\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf04983b-d4b7-4dd8-9cf2-99e544d209a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46fed9a9-a99a-4a2e-be43-511e7bd63d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241016_074036\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          12\n",
      "Memory Avail:       13.45 GB / 15.31 GB (87.8%)\n",
      "Disk Space Avail:   28.57 GB / 237.85 GB (12.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241016_074036\"\n",
      "Train Data Rows:    2138\n",
      "Train Data Columns: 11\n",
      "Label Column:       AAPL.O\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (193.98, 27.44, 93.45608, 40.55149)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13770.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 11 | ['MSFT.O', 'INTC.O', 'AMZN.O', 'GS.N', 'SPY', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 11 | ['MSFT.O', 'INTC.O', 'AMZN.O', 'GS.N', 'SPY', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t11 features in original data used to generate 11 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1710, Val Rows: 428\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-2.705\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-2.4646\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.5753\n",
      "[2000]\tvalid_set's rmse: 2.35887\n",
      "[3000]\tvalid_set's rmse: 2.25556\n",
      "[4000]\tvalid_set's rmse: 2.19107\n",
      "[5000]\tvalid_set's rmse: 2.16314\n",
      "[6000]\tvalid_set's rmse: 2.13663\n",
      "[7000]\tvalid_set's rmse: 2.12106\n",
      "[8000]\tvalid_set's rmse: 2.11146\n",
      "[9000]\tvalid_set's rmse: 2.10121\n",
      "[10000]\tvalid_set's rmse: 2.09719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.0963\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.27238\n",
      "[2000]\tvalid_set's rmse: 2.24883\n",
      "[3000]\tvalid_set's rmse: 2.2454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.2447\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.41s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-2.2494\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-2.062\t = Validation score   (-root_mean_squared_error)\n",
      "\t63.88s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-1.9422\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-3.9172\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-2.4132\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-3.3689\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-2.2267\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesMSE': 0.526, 'LightGBMXT': 0.211, 'CatBoost': 0.158, 'LightGBMLarge': 0.105}\n",
      "\t-1.8916\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 92.7s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1784.4 rows/s (428 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241016_074036\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score :  {'root_mean_squared_error': -0.8450010308402383, 'mean_squared_error': -0.7140267421210653, 'mean_absolute_error': -0.4835061374134655, 'r2': 0.9995821547029934, 'pearsonr': 0.9997927097343956, 'median_absolute_error': -0.26528778076172443}\n",
      "Best model :  WeightedEnsemble_L2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206010/2729859190.py:16: DeprecationWarning: `get_model_best` has been deprecated and will be removed in version 1.2. Please use `model_best` instead. This will raise an error in the future!\n",
      "  print(\"Best model : \", model.get_model_best())\n"
     ]
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "train_data = data.dropna()\n",
    "\n",
    "# 타겟 열 설정\n",
    "target_column = 'AAPL.O'\n",
    "\n",
    "# 모델 학습\n",
    "model = TabularPredictor(label=target_column).fit(train_data)\n",
    "# 학습 데이터에서 일부를 검증용으로 샘플링\n",
    "test_data = train_data.sample(frac=0.3, random_state=10)\n",
    "\n",
    "# 예측 수행\n",
    "pred = model.predict(test_data)\n",
    "# 모델 평가 및 결과 \n",
    "print(\"Train score : \", model.evaluate(test_data))\n",
    "print(\"Best model : \", model.get_model_best())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7624a-190a-40dd-9dce-c5832a6d5cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d37481-067b-4f27-bafc-e584580c52fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d31482-2bbb-4415-8a39-f731a230da66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7369a4-8f89-40ee-807a-104fd3cefade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4f60e-7730-49da-9848-27a2232d3c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f6061-eced-4620-94c4-70a60e44ab5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a641d-5ea4-4d1f-8d56-d072ca2770ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7ef9e-521e-4d76-8a20-cdeadd2b653d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
