{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eeaeb82-5790-41e8-b7cf-60667bc59627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707cd1eb-37c2-4352-9215-82b410883b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/member.csv\")\n",
    "tran = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/transaction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33251c8-8652-42c6-9e22-eeddbca57018",
   "metadata": {},
   "source": [
    "* 쇼핑몰 고객 데이터, 프로모션 쿠폰을 발행하고 사용 여부 데이터를 수집\n",
    "* mem: 고객id, 최근 방문일, 사는지역, 추천여부, 주요접속채널, 쿠폰 사용 여부\n",
    "* transaction: 고객id, 구매수량, 총 구매금액 정보가 있음\n",
    "* 전통적 마케팅 분석 방법인 RFM 기법을 사용해 고객 데이터에서 파생변수 생성 후 분석\n",
    "* Recency: 현재일 - 최근 구매일\n",
    "* Frequency: 구매 빈도\n",
    "* Monetary: 구매 금액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18a1947-1c2a-4cca-b812-c92683105a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recency</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>is_referral</th>\n",
       "      <th>channel</th>\n",
       "      <th>conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>906145</td>\n",
       "      <td>10</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184478</td>\n",
       "      <td>6</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394235</td>\n",
       "      <td>7</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130152</td>\n",
       "      <td>9</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>940352</td>\n",
       "      <td>2</td>\n",
       "      <td>Urban</td>\n",
       "      <td>0</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  recency   zip_code  is_referral channel  conversion\n",
       "0  906145       10  Surburban            0   Phone           0\n",
       "1  184478        6      Rural            1     Web           0\n",
       "2  394235        7  Surburban            1     Web           0\n",
       "3  130152        9      Rural            1     Web           0\n",
       "4  940352        2      Urban            0     Web           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00bbc01b-a797-4490-af6e-e8a09641fddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_item</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>906145</td>\n",
       "      <td>5</td>\n",
       "      <td>34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>906145</td>\n",
       "      <td>1</td>\n",
       "      <td>27000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>906145</td>\n",
       "      <td>4</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184478</td>\n",
       "      <td>4</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394235</td>\n",
       "      <td>4</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  num_item  total_amount\n",
       "0  906145         5         34000\n",
       "1  906145         1         27000\n",
       "2  906145         4         33000\n",
       "3  184478         4         29000\n",
       "4  394235         4         33000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afac66-55bf-4109-bee3-640474d17fa5",
   "metadata": {},
   "source": [
    "* id : 아이디 (의미가 없는 컬럼으로 추후 드랍예정이다.)\n",
    "* recency : 최근이용을 언제 했었나 (10일전, 6일전 ..)\n",
    "* zip_code : 우편번호 (한번 가공이 된 상태)\n",
    "* is_referral : 추천인이 있고 없음 으로 가입을 했는지\n",
    "* channe : 서비스 이용 채널 (폰, 웹 )\n",
    "* conversion : 프로모션을 받고 나서 고객이 구입을 했는지 안했는지 (우리가 예측하고자 하는 컬럼/종속변수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b45e7-e5a4-4204-b986-7fa5a6768b13",
   "metadata": {},
   "source": [
    "* 데이터 컬럼 살펴보기\n",
    "* id : 아이디 (의미가 없는 컬럼으로 추후 드랍예정이다.)\n",
    "* num_item : 한 거래에 몇개에 아이템을 구매 했는지\n",
    "* total_amount : 총 금액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65386c75-f5e5-44b6-8bfd-c22e5d7656fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc18a3c-f980-4893-8e2c-0de52bf7acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64000 entries, 0 to 63999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           64000 non-null  int64 \n",
      " 1   recency      64000 non-null  int64 \n",
      " 2   zip_code     64000 non-null  object\n",
      " 3   is_referral  64000 non-null  int64 \n",
      " 4   channel      64000 non-null  object\n",
      " 5   conversion   64000 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "mem.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6800ea6-8b49-4795-9298-4c1dad5d9393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "recency        0\n",
       "zip_code       0\n",
       "is_referral    0\n",
       "channel        0\n",
       "conversion     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5389e4f-6239-4b42-a3a2-f695d78ae9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196836 entries, 0 to 196835\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype\n",
      "---  ------        --------------   -----\n",
      " 0   id            196836 non-null  int64\n",
      " 1   num_item      196836 non-null  int64\n",
      " 2   total_amount  196836 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "tran.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d763978-1ca9-4073-94b9-57818bf14983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "num_item        0\n",
       "total_amount    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72249b-e673-4525-9ebc-e7767eaf6b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e45b23-b79b-46cc-a056-160fa8189eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     64000.000000\n",
       "mean     550694.137797\n",
       "std      259105.689773\n",
       "min      100001.000000\n",
       "25%      326772.000000\n",
       "50%      551300.000000\n",
       "75%      774914.500000\n",
       "max      999997.000000\n",
       "Name: id, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem['id'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f07f7-f803-4e19-bcc2-112a9a4e4a2a",
   "metadata": {},
   "source": [
    "m_mini = 326772.000000 - (1.5 * (774914.500000 - 326772.000000))\n",
    "m_max = 774914.500000 + (1.5 * (774914.500000 - 326772.000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01dc30-3da6-411f-b634-403de149b45b",
   "metadata": {},
   "source": [
    "print(\"minimun :\", m_mini)\n",
    "print(\"maximun :\", m_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db871c-e07f-4bc4-abd9-b3b5bee2e173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d91174a3-be7b-4fd7-a9f0-6143f0d418f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196836 entries, 0 to 196835\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype\n",
      "---  ------        --------------   -----\n",
      " 0   id            196836 non-null  int64\n",
      " 1   num_item      196836 non-null  int64\n",
      " 2   total_amount  196836 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "tran.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74d0d546-86e7-487d-8102-6ff315fe4499",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran['avg_price'] = tran['total_amount'] / tran['num_item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac7a6969-2d02-4a0d-942e-356dbba02f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196836 entries, 0 to 196835\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            196836 non-null  int64  \n",
      " 1   num_item      196836 non-null  int64  \n",
      " 2   total_amount  196836 non-null  int64  \n",
      " 3   avg_price     196836 non-null  float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "tran.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6778190f-fda8-4568-9ef5-30c8139c60d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6800.0\n",
       "1    27000.0\n",
       "2     8250.0\n",
       "3     7250.0\n",
       "4     8250.0\n",
       "Name: avg_price, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran['avg_price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "674e67b2-cf3e-4766-ad9a-9c0c1108d945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_item</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>26000.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100008</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>26000.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100032</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>20666.666667</td>\n",
       "      <td>9366.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100036</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25800.000000</td>\n",
       "      <td>13273.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100070</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>21250.000000</td>\n",
       "      <td>8537.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999932</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>32000.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999981</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>22750.000000</td>\n",
       "      <td>12875.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999990</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>10388.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>27000.000000</td>\n",
       "      <td>13500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>6500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_item  total_amount     avg_price\n",
       "id                                          \n",
       "100001  3.500000  26000.000000   7500.000000\n",
       "100008  5.000000  26000.000000   5200.000000\n",
       "100032  2.666667  20666.666667   9366.666667\n",
       "100036  3.000000  25800.000000  13273.333333\n",
       "100070  3.250000  21250.000000   8537.500000\n",
       "...          ...           ...           ...\n",
       "999932  5.000000  32000.000000   6400.000000\n",
       "999981  2.000000  22750.000000  12875.000000\n",
       "999990  3.000000  28000.000000  10388.888889\n",
       "999995  2.000000  27000.000000  13500.000000\n",
       "999997  2.000000  13000.000000   6500.000000\n",
       "\n",
       "[64000 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran.groupby('id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbeb05fd-14e2-44bc-9525-b39e2e4965d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id      num_item  total_amount  avg_price   \n",
       "100001  3         24000         8000.000000     1\n",
       "        4         28000         7000.000000     1\n",
       "100008  5         26000         5200.000000     1\n",
       "100032  1         11000         11000.000000    1\n",
       "        2         23000         11500.000000    1\n",
       "                                               ..\n",
       "999990  2         30000         15000.000000    1\n",
       "        3         32000         10666.666667    1\n",
       "        4         22000         5500.000000     1\n",
       "999995  2         27000         13500.000000    1\n",
       "999997  2         13000         6500.000000     1\n",
       "Name: count, Length: 194954, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran.groupby('id').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83dd0981-75c3-404a-b969-d3a2c6cd156e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "691067    5\n",
       "720147    5\n",
       "422265    5\n",
       "670720    5\n",
       "154620    5\n",
       "         ..\n",
       "881780    1\n",
       "154471    1\n",
       "480462    1\n",
       "126129    1\n",
       "156423    1\n",
       "Name: count, Length: 64000, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347c083-fc7b-473f-86aa-39a2a522b3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe919d06-923b-4aae-95ed-717439eb6f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80413b-3748-447f-b710-45354450f2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a83fca1f-b148-4dd7-9977-5bd3376f8c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88ec740e-25e5-4a4c-baf2-c491d2e7a57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6e726-952b-466d-a35c-f93aae20da9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d3a4e7-eb07-471c-9f2a-09c372eb2c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1efb2e-72e8-448b-a2f5-906b8a23a103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cab657-c951-4b14-a4ad-67cc6dd61930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9e502-8402-4c76-9cdd-9a24cf9ba2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e65a29-9501-47b1-b6b5-189f4583c5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a610cae-e7bc-4017-8647-6d02ea89ee2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d704c-b448-40f4-93a2-0e3ba4f6b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698e3f1-a0aa-4c74-96ee-2f0045034b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2628a-ce1d-4cca-b75f-3a9732a7b611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead99ea-74e3-4b80-a69d-29772c935c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf5ab2-9dbe-4e9d-9c16-4d934a97e76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54547179-b24c-4062-9f6d-032e3dd5aaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb6aa9-121f-4193-94c5-953a0e29add0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed41e564-d93e-48be-95ff-18c4183c0367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5319766c-7fac-4717-8553-855c8a3edbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64000 entries, 0 to 63999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           64000 non-null  int64 \n",
      " 1   recency      64000 non-null  int64 \n",
      " 2   zip_code     64000 non-null  object\n",
      " 3   is_referral  64000 non-null  int64 \n",
      " 4   channel      64000 non-null  object\n",
      " 5   conversion   64000 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "mem.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88c6f844-39b5-488d-83dd-e41a1cc99164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  6,  7,  9,  2,  1,  5,  4,  3, 11, 12,  8], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem['recency'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c49b2f22-d738-4dab-991d-8593d3f97be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem['recency'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff5c1b-0e90-4841-bc37-85b7090bf9e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "mem['recency'] 값이 작을수록 Frquency 구매빈도는 높다?라고 말할 수 있나?\n",
    "값이 작고 총 금액이나 평균이 크면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84320cf1-677a-4e56-a5f1-af3a02531203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d401f3d-997a-4e24-9bbe-e70c6998b043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c5593-8a30-4c23-abd7-b5910d3a2c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6550f93-3f37-4e5b-aa33-15e06821c9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece9726-9646-4a77-bdd6-67865aa72509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b1c86fa-c8c6-425b-b962-d31f5c8794fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(mem, tran, on='id', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e594377-c47b-441d-8744-087ee68c18e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recency</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>is_referral</th>\n",
       "      <th>channel</th>\n",
       "      <th>conversion</th>\n",
       "      <th>num_item</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24000</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28000</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100008</td>\n",
       "      <td>3</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26000</td>\n",
       "      <td>5200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100032</td>\n",
       "      <td>11</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>28000</td>\n",
       "      <td>5600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100032</td>\n",
       "      <td>11</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11000</td>\n",
       "      <td>11000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  recency zip_code  is_referral channel  conversion  num_item  \\\n",
       "0  100001        6    Urban            1   Phone           0         3   \n",
       "1  100001        6    Urban            1   Phone           0         4   \n",
       "2  100008        3    Urban            1     Web           0         5   \n",
       "3  100032       11    Urban            1   Phone           0         5   \n",
       "4  100032       11    Urban            1   Phone           0         1   \n",
       "\n",
       "   total_amount  avg_price  \n",
       "0         24000     8000.0  \n",
       "1         28000     7000.0  \n",
       "2         26000     5200.0  \n",
       "3         28000     5600.0  \n",
       "4         11000    11000.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a27bba7-658d-4415-a739-fd56ab0486fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196836 entries, 0 to 196835\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            196836 non-null  int64  \n",
      " 1   recency       196836 non-null  int64  \n",
      " 2   zip_code      196836 non-null  object \n",
      " 3   is_referral   196836 non-null  int64  \n",
      " 4   channel       196836 non-null  object \n",
      " 5   conversion    196836 non-null  int64  \n",
      " 6   num_item      196836 non-null  int64  \n",
      " 7   total_amount  196836 non-null  int64  \n",
      " 8   avg_price     196836 non-null  float64\n",
      "dtypes: float64(1), int64(6), object(2)\n",
      "memory usage: 13.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0df8fca7-ae27-4c2e-9db5-903acad905a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "recency         0\n",
       "zip_code        0\n",
       "is_referral     0\n",
       "channel         0\n",
       "conversion      0\n",
       "num_item        0\n",
       "total_amount    0\n",
       "avg_price       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46857ab2-f632-4a7e-905c-3bbebdd562c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_referral'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcae1578-e20a-4866-9f33-467126d0f409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Urban', 'Surburban', 'Rural'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['zip_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ba8a322-61dd-4d08-8e06-43d9ae296b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Phone', 'Web', 'Multichannel'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['channel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a703959-1069-4154-8b56-711a8b9f001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196836 entries, 0 to 196835\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            196836 non-null  int64  \n",
      " 1   recency       196836 non-null  int64  \n",
      " 2   zip_code      196836 non-null  object \n",
      " 3   is_referral   196836 non-null  int64  \n",
      " 4   channel       196836 non-null  object \n",
      " 5   conversion    196836 non-null  int64  \n",
      " 6   num_item      196836 non-null  int64  \n",
      " 7   total_amount  196836 non-null  int64  \n",
      " 8   avg_price     196836 non-null  float64\n",
      "dtypes: float64(1), int64(6), object(2)\n",
      "memory usage: 13.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "364d4b05-4cd1-4873-948f-81ec0860576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recency</th>\n",
       "      <th>is_referral</th>\n",
       "      <th>conversion</th>\n",
       "      <th>num_item</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>zip_code_Surburban</th>\n",
       "      <th>zip_code_Urban</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>channel_Web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100008</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100032</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>28000</td>\n",
       "      <td>5600.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100032</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196831</th>\n",
       "      <td>999990</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32000</td>\n",
       "      <td>10666.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196832</th>\n",
       "      <td>999990</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196833</th>\n",
       "      <td>999990</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196834</th>\n",
       "      <td>999995</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27000</td>\n",
       "      <td>13500.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196835</th>\n",
       "      <td>999997</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13000</td>\n",
       "      <td>6500.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196836 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  recency  is_referral  conversion  num_item  total_amount  \\\n",
       "0       100001        6            1           0         3         24000   \n",
       "1       100001        6            1           0         4         28000   \n",
       "2       100008        3            1           0         5         26000   \n",
       "3       100032       11            1           0         5         28000   \n",
       "4       100032       11            1           0         1         11000   \n",
       "...        ...      ...          ...         ...       ...           ...   \n",
       "196831  999990        8            1           0         3         32000   \n",
       "196832  999990        8            1           0         2         30000   \n",
       "196833  999990        8            1           0         4         22000   \n",
       "196834  999995        3            1           0         2         27000   \n",
       "196835  999997        4            0           0         2         13000   \n",
       "\n",
       "           avg_price  zip_code_Surburban  zip_code_Urban  channel_Phone  \\\n",
       "0        8000.000000               False            True           True   \n",
       "1        7000.000000               False            True           True   \n",
       "2        5200.000000               False            True          False   \n",
       "3        5600.000000               False            True           True   \n",
       "4       11000.000000               False            True           True   \n",
       "...              ...                 ...             ...            ...   \n",
       "196831  10666.666667               False           False           True   \n",
       "196832  15000.000000               False           False           True   \n",
       "196833   5500.000000               False           False           True   \n",
       "196834  13500.000000                True           False           True   \n",
       "196835   6500.000000                True           False          False   \n",
       "\n",
       "        channel_Web  \n",
       "0             False  \n",
       "1             False  \n",
       "2              True  \n",
       "3             False  \n",
       "4             False  \n",
       "...             ...  \n",
       "196831        False  \n",
       "196832        False  \n",
       "196833        False  \n",
       "196834        False  \n",
       "196835        False  \n",
       "\n",
       "[196836 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data, columns=['zip_code', 'channel'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f9e8e52-261b-421d-96d1-aa5135767ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['zip_code', 'channel'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84ac355c-2ded-41f0-8464-54a773ce43aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196836 entries, 0 to 196835\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  196836 non-null  int64  \n",
      " 1   recency             196836 non-null  int64  \n",
      " 2   is_referral         196836 non-null  int64  \n",
      " 3   conversion          196836 non-null  int64  \n",
      " 4   num_item            196836 non-null  int64  \n",
      " 5   total_amount        196836 non-null  int64  \n",
      " 6   avg_price           196836 non-null  float64\n",
      " 7   zip_code_Surburban  196836 non-null  bool   \n",
      " 8   zip_code_Urban      196836 non-null  bool   \n",
      " 9   channel_Phone       196836 non-null  bool   \n",
      " 10  channel_Web         196836 non-null  bool   \n",
      "dtypes: bool(4), float64(1), int64(6)\n",
      "memory usage: 11.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb109f76-f0d6-488b-87a9-035e6201167e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "mem['recency'] 값이 작을수록 Frquency 구매빈도는 높다?라고 말할 수 있나?\n",
    "값이 작고 총 금액이나 평균이 크면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f9dfc-6ca4-49f3-aff7-5fbcb1532a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38e5aaef-246d-4f62-b5b1-2fe3e7192289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recency  avg_price   \n",
       "1        6000.000000     797\n",
       "         5000.000000     756\n",
       "         7000.000000     743\n",
       "         4000.000000     729\n",
       "         8000.000000     710\n",
       "                        ... \n",
       "12       1500.000000       4\n",
       "         7400.000000       4\n",
       "         38000.000000      4\n",
       "         3166.666667       2\n",
       "         4833.333333       1\n",
       "Name: count, Length: 1536, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('recency')['avg_price'].value_counts(sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdddd93d-a0ad-4cee-a4ed-ea2cae07209d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>avg_price</th>\n",
       "      <th>1500.000000</th>\n",
       "      <th>1600.000000</th>\n",
       "      <th>1666.666667</th>\n",
       "      <th>1800.000000</th>\n",
       "      <th>1833.333333</th>\n",
       "      <th>2000.000000</th>\n",
       "      <th>2166.666667</th>\n",
       "      <th>2200.000000</th>\n",
       "      <th>2250.000000</th>\n",
       "      <th>2333.333333</th>\n",
       "      <th>...</th>\n",
       "      <th>29000.000000</th>\n",
       "      <th>30000.000000</th>\n",
       "      <th>31000.000000</th>\n",
       "      <th>32000.000000</th>\n",
       "      <th>33000.000000</th>\n",
       "      <th>34000.000000</th>\n",
       "      <th>35000.000000</th>\n",
       "      <th>36000.000000</th>\n",
       "      <th>37000.000000</th>\n",
       "      <th>38000.000000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recency</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>166</td>\n",
       "      <td>36</td>\n",
       "      <td>183</td>\n",
       "      <td>29</td>\n",
       "      <td>373</td>\n",
       "      <td>37</td>\n",
       "      <td>185</td>\n",
       "      <td>184</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>187</td>\n",
       "      <td>165</td>\n",
       "      <td>186</td>\n",
       "      <td>212</td>\n",
       "      <td>157</td>\n",
       "      <td>202</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>133</td>\n",
       "      <td>33</td>\n",
       "      <td>149</td>\n",
       "      <td>34</td>\n",
       "      <td>339</td>\n",
       "      <td>32</td>\n",
       "      <td>162</td>\n",
       "      <td>136</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>141</td>\n",
       "      <td>168</td>\n",
       "      <td>167</td>\n",
       "      <td>163</td>\n",
       "      <td>173</td>\n",
       "      <td>165</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>120</td>\n",
       "      <td>17</td>\n",
       "      <td>119</td>\n",
       "      <td>23</td>\n",
       "      <td>245</td>\n",
       "      <td>20</td>\n",
       "      <td>118</td>\n",
       "      <td>129</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>125</td>\n",
       "      <td>137</td>\n",
       "      <td>149</td>\n",
       "      <td>125</td>\n",
       "      <td>112</td>\n",
       "      <td>124</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>19</td>\n",
       "      <td>216</td>\n",
       "      <td>18</td>\n",
       "      <td>122</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>109</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>111</td>\n",
       "      <td>104</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>215</td>\n",
       "      <td>16</td>\n",
       "      <td>88</td>\n",
       "      <td>101</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>105</td>\n",
       "      <td>69</td>\n",
       "      <td>99</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>96</td>\n",
       "      <td>103</td>\n",
       "      <td>109</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>160</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>105</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>149</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>66</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>126</td>\n",
       "      <td>15</td>\n",
       "      <td>112</td>\n",
       "      <td>14</td>\n",
       "      <td>277</td>\n",
       "      <td>13</td>\n",
       "      <td>127</td>\n",
       "      <td>136</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>167</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>135</td>\n",
       "      <td>143</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>149</td>\n",
       "      <td>16</td>\n",
       "      <td>157</td>\n",
       "      <td>12</td>\n",
       "      <td>309</td>\n",
       "      <td>14</td>\n",
       "      <td>181</td>\n",
       "      <td>154</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>149</td>\n",
       "      <td>169</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>89</td>\n",
       "      <td>79</td>\n",
       "      <td>93</td>\n",
       "      <td>74</td>\n",
       "      <td>89</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "avg_price  1500.000000   1600.000000   1666.666667   1800.000000   \\\n",
       "recency                                                             \n",
       "1                    44           166            36           183   \n",
       "2                    23           133            33           149   \n",
       "3                    17           120            17           119   \n",
       "4                    19            94            12            93   \n",
       "5                    13            87            18            84   \n",
       "6                     9            87            11            96   \n",
       "7                     9            68            11           104   \n",
       "8                     8            54             7            74   \n",
       "9                    18           126            15           112   \n",
       "10                   15           149            16           157   \n",
       "11                    7            54            12            74   \n",
       "12                    4            42             6            49   \n",
       "\n",
       "avg_price  1833.333333   2000.000000   2166.666667   2200.000000   \\\n",
       "recency                                                             \n",
       "1                    29           373            37           185   \n",
       "2                    34           339            32           162   \n",
       "3                    23           245            20           118   \n",
       "4                    19           216            18           122   \n",
       "5                    18           215            16            88   \n",
       "6                     8           179            11            81   \n",
       "7                     9           160             9            91   \n",
       "8                     7           149            10            66   \n",
       "9                    14           277            13           127   \n",
       "10                   12           309            14           181   \n",
       "11                   11           139             9            73   \n",
       "12                    5           106             5            53   \n",
       "\n",
       "avg_price  2250.000000   2333.333333   ...  29000.000000  30000.000000  \\\n",
       "recency                                ...                               \n",
       "1                   184            35  ...           210           187   \n",
       "2                   136            32  ...           186           141   \n",
       "3                   129            12  ...           109           125   \n",
       "4                    98            14  ...           111           109   \n",
       "5                   101            15  ...            90           109   \n",
       "6                    80            15  ...           109            96   \n",
       "7                   105             9  ...            89            70   \n",
       "8                    63            12  ...            76            77   \n",
       "9                   136            16  ...           123           123   \n",
       "10                  154            23  ...           149           169   \n",
       "11                   75             5  ...            83            89   \n",
       "12                   45             7  ...            58            45   \n",
       "\n",
       "avg_price  31000.000000  32000.000000  33000.000000  34000.000000  \\\n",
       "recency                                                             \n",
       "1                   165           186           212           157   \n",
       "2                   168           167           163           173   \n",
       "3                   137           149           125           112   \n",
       "4                   111            95            77           111   \n",
       "5                   108           105            69            99   \n",
       "6                   103           109            90            80   \n",
       "7                    91            90            93            76   \n",
       "8                    93            68            66            76   \n",
       "9                   167           123           125           135   \n",
       "10                  166           182           181           147   \n",
       "11                   79            93            74            89   \n",
       "12                   51            41            58            36   \n",
       "\n",
       "avg_price  35000.000000  36000.000000  37000.000000  38000.000000  \n",
       "recency                                                            \n",
       "1                   202            38            26            37  \n",
       "2                   165            30            22            18  \n",
       "3                   124             9            18            23  \n",
       "4                   104            15            17            12  \n",
       "5                   107             7            14            15  \n",
       "6                    92            14             9            11  \n",
       "7                    77            12            11             7  \n",
       "8                    79            10            10            13  \n",
       "9                   143            15            18            18  \n",
       "10                  148            16            16            14  \n",
       "11                   72             4             7            10  \n",
       "12                   51             8             6             4  \n",
       "\n",
       "[12 rows x 128 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('recency')['avg_price'].value_counts(sort=True).unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbc754de-3eff-4804-b3ae-92a09efa596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>total_amount</th>\n",
       "      <th>8000</th>\n",
       "      <th>9000</th>\n",
       "      <th>10000</th>\n",
       "      <th>11000</th>\n",
       "      <th>12000</th>\n",
       "      <th>13000</th>\n",
       "      <th>14000</th>\n",
       "      <th>15000</th>\n",
       "      <th>16000</th>\n",
       "      <th>17000</th>\n",
       "      <th>...</th>\n",
       "      <th>29000</th>\n",
       "      <th>30000</th>\n",
       "      <th>31000</th>\n",
       "      <th>32000</th>\n",
       "      <th>33000</th>\n",
       "      <th>34000</th>\n",
       "      <th>35000</th>\n",
       "      <th>36000</th>\n",
       "      <th>37000</th>\n",
       "      <th>38000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recency</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>809</td>\n",
       "      <td>998</td>\n",
       "      <td>1009</td>\n",
       "      <td>965</td>\n",
       "      <td>919</td>\n",
       "      <td>957</td>\n",
       "      <td>1041</td>\n",
       "      <td>1011</td>\n",
       "      <td>980</td>\n",
       "      <td>954</td>\n",
       "      <td>...</td>\n",
       "      <td>987</td>\n",
       "      <td>967</td>\n",
       "      <td>987</td>\n",
       "      <td>940</td>\n",
       "      <td>1018</td>\n",
       "      <td>896</td>\n",
       "      <td>967</td>\n",
       "      <td>174</td>\n",
       "      <td>211</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672</td>\n",
       "      <td>798</td>\n",
       "      <td>826</td>\n",
       "      <td>814</td>\n",
       "      <td>815</td>\n",
       "      <td>863</td>\n",
       "      <td>820</td>\n",
       "      <td>817</td>\n",
       "      <td>876</td>\n",
       "      <td>829</td>\n",
       "      <td>...</td>\n",
       "      <td>829</td>\n",
       "      <td>801</td>\n",
       "      <td>862</td>\n",
       "      <td>852</td>\n",
       "      <td>860</td>\n",
       "      <td>878</td>\n",
       "      <td>819</td>\n",
       "      <td>162</td>\n",
       "      <td>153</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>498</td>\n",
       "      <td>661</td>\n",
       "      <td>633</td>\n",
       "      <td>630</td>\n",
       "      <td>636</td>\n",
       "      <td>649</td>\n",
       "      <td>607</td>\n",
       "      <td>612</td>\n",
       "      <td>594</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>650</td>\n",
       "      <td>616</td>\n",
       "      <td>627</td>\n",
       "      <td>698</td>\n",
       "      <td>676</td>\n",
       "      <td>658</td>\n",
       "      <td>648</td>\n",
       "      <td>111</td>\n",
       "      <td>116</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "      <td>522</td>\n",
       "      <td>537</td>\n",
       "      <td>566</td>\n",
       "      <td>556</td>\n",
       "      <td>523</td>\n",
       "      <td>558</td>\n",
       "      <td>568</td>\n",
       "      <td>555</td>\n",
       "      <td>558</td>\n",
       "      <td>...</td>\n",
       "      <td>561</td>\n",
       "      <td>527</td>\n",
       "      <td>568</td>\n",
       "      <td>538</td>\n",
       "      <td>548</td>\n",
       "      <td>553</td>\n",
       "      <td>571</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>461</td>\n",
       "      <td>504</td>\n",
       "      <td>486</td>\n",
       "      <td>492</td>\n",
       "      <td>500</td>\n",
       "      <td>535</td>\n",
       "      <td>478</td>\n",
       "      <td>519</td>\n",
       "      <td>483</td>\n",
       "      <td>504</td>\n",
       "      <td>...</td>\n",
       "      <td>488</td>\n",
       "      <td>497</td>\n",
       "      <td>479</td>\n",
       "      <td>495</td>\n",
       "      <td>483</td>\n",
       "      <td>461</td>\n",
       "      <td>504</td>\n",
       "      <td>71</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>439</td>\n",
       "      <td>467</td>\n",
       "      <td>481</td>\n",
       "      <td>486</td>\n",
       "      <td>519</td>\n",
       "      <td>535</td>\n",
       "      <td>499</td>\n",
       "      <td>525</td>\n",
       "      <td>507</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>507</td>\n",
       "      <td>487</td>\n",
       "      <td>513</td>\n",
       "      <td>538</td>\n",
       "      <td>470</td>\n",
       "      <td>483</td>\n",
       "      <td>494</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>337</td>\n",
       "      <td>482</td>\n",
       "      <td>451</td>\n",
       "      <td>461</td>\n",
       "      <td>430</td>\n",
       "      <td>481</td>\n",
       "      <td>456</td>\n",
       "      <td>426</td>\n",
       "      <td>434</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>429</td>\n",
       "      <td>428</td>\n",
       "      <td>440</td>\n",
       "      <td>456</td>\n",
       "      <td>455</td>\n",
       "      <td>409</td>\n",
       "      <td>431</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>295</td>\n",
       "      <td>354</td>\n",
       "      <td>376</td>\n",
       "      <td>376</td>\n",
       "      <td>380</td>\n",
       "      <td>382</td>\n",
       "      <td>398</td>\n",
       "      <td>415</td>\n",
       "      <td>384</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>363</td>\n",
       "      <td>377</td>\n",
       "      <td>406</td>\n",
       "      <td>376</td>\n",
       "      <td>392</td>\n",
       "      <td>386</td>\n",
       "      <td>365</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>621</td>\n",
       "      <td>689</td>\n",
       "      <td>684</td>\n",
       "      <td>703</td>\n",
       "      <td>720</td>\n",
       "      <td>697</td>\n",
       "      <td>679</td>\n",
       "      <td>699</td>\n",
       "      <td>722</td>\n",
       "      <td>731</td>\n",
       "      <td>...</td>\n",
       "      <td>738</td>\n",
       "      <td>710</td>\n",
       "      <td>708</td>\n",
       "      <td>678</td>\n",
       "      <td>683</td>\n",
       "      <td>690</td>\n",
       "      <td>683</td>\n",
       "      <td>84</td>\n",
       "      <td>96</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>735</td>\n",
       "      <td>788</td>\n",
       "      <td>838</td>\n",
       "      <td>817</td>\n",
       "      <td>840</td>\n",
       "      <td>823</td>\n",
       "      <td>784</td>\n",
       "      <td>876</td>\n",
       "      <td>763</td>\n",
       "      <td>822</td>\n",
       "      <td>...</td>\n",
       "      <td>847</td>\n",
       "      <td>851</td>\n",
       "      <td>823</td>\n",
       "      <td>827</td>\n",
       "      <td>820</td>\n",
       "      <td>824</td>\n",
       "      <td>809</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>305</td>\n",
       "      <td>392</td>\n",
       "      <td>353</td>\n",
       "      <td>391</td>\n",
       "      <td>375</td>\n",
       "      <td>381</td>\n",
       "      <td>395</td>\n",
       "      <td>391</td>\n",
       "      <td>390</td>\n",
       "      <td>369</td>\n",
       "      <td>...</td>\n",
       "      <td>383</td>\n",
       "      <td>420</td>\n",
       "      <td>350</td>\n",
       "      <td>406</td>\n",
       "      <td>397</td>\n",
       "      <td>394</td>\n",
       "      <td>386</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>229</td>\n",
       "      <td>245</td>\n",
       "      <td>250</td>\n",
       "      <td>259</td>\n",
       "      <td>274</td>\n",
       "      <td>255</td>\n",
       "      <td>252</td>\n",
       "      <td>237</td>\n",
       "      <td>249</td>\n",
       "      <td>257</td>\n",
       "      <td>...</td>\n",
       "      <td>258</td>\n",
       "      <td>259</td>\n",
       "      <td>260</td>\n",
       "      <td>263</td>\n",
       "      <td>270</td>\n",
       "      <td>240</td>\n",
       "      <td>271</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "total_amount  8000   9000   10000  11000  12000  13000  14000  15000  16000  \\\n",
       "recency                                                                       \n",
       "1               809    998   1009    965    919    957   1041   1011    980   \n",
       "2               672    798    826    814    815    863    820    817    876   \n",
       "3               498    661    633    630    636    649    607    612    594   \n",
       "4               480    522    537    566    556    523    558    568    555   \n",
       "5               461    504    486    492    500    535    478    519    483   \n",
       "6               439    467    481    486    519    535    499    525    507   \n",
       "7               337    482    451    461    430    481    456    426    434   \n",
       "8               295    354    376    376    380    382    398    415    384   \n",
       "9               621    689    684    703    720    697    679    699    722   \n",
       "10              735    788    838    817    840    823    784    876    763   \n",
       "11              305    392    353    391    375    381    395    391    390   \n",
       "12              229    245    250    259    274    255    252    237    249   \n",
       "\n",
       "total_amount  17000  ...  29000  30000  31000  32000  33000  34000  35000  \\\n",
       "recency              ...                                                    \n",
       "1               954  ...    987    967    987    940   1018    896    967   \n",
       "2               829  ...    829    801    862    852    860    878    819   \n",
       "3               615  ...    650    616    627    698    676    658    648   \n",
       "4               558  ...    561    527    568    538    548    553    571   \n",
       "5               504  ...    488    497    479    495    483    461    504   \n",
       "6               476  ...    507    487    513    538    470    483    494   \n",
       "7               426  ...    429    428    440    456    455    409    431   \n",
       "8               400  ...    363    377    406    376    392    386    365   \n",
       "9               731  ...    738    710    708    678    683    690    683   \n",
       "10              822  ...    847    851    823    827    820    824    809   \n",
       "11              369  ...    383    420    350    406    397    394    386   \n",
       "12              257  ...    258    259    260    263    270    240    271   \n",
       "\n",
       "total_amount  36000  37000  38000  \n",
       "recency                            \n",
       "1               174    211    209  \n",
       "2               162    153    132  \n",
       "3               111    116    113  \n",
       "4                78     75     73  \n",
       "5                71     66     77  \n",
       "6                78     76     83  \n",
       "7                66     77     63  \n",
       "8                55     45     48  \n",
       "9                84     96     91  \n",
       "10               87     93    105  \n",
       "11               57     58     45  \n",
       "12               41     38     35  \n",
       "\n",
       "[12 rows x 31 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('recency')['total_amount'].value_counts(sort=True).unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6fe516-86be-4a26-8ba9-bdc78919f42e",
   "metadata": {},
   "source": [
    "* recency랑 total\n",
    "* recency이 작으면 total_amount가 높다\n",
    "* purchase_intensity : recency가 작을수록 구매 강도가 높다는 가정을 나타내는 용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "640c3f43-79da-4647-a8d4-01a4f3a16e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purchase_intensity'] = data['total_amount'] / data['recency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dfe7653-b97d-442f-8918-c33aeff4f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196836 entries, 0 to 196835\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  196836 non-null  int64  \n",
      " 1   recency             196836 non-null  int64  \n",
      " 2   is_referral         196836 non-null  int64  \n",
      " 3   conversion          196836 non-null  int64  \n",
      " 4   num_item            196836 non-null  int64  \n",
      " 5   total_amount        196836 non-null  int64  \n",
      " 6   avg_price           196836 non-null  float64\n",
      " 7   zip_code_Surburban  196836 non-null  bool   \n",
      " 8   zip_code_Urban      196836 non-null  bool   \n",
      " 9   channel_Phone       196836 non-null  bool   \n",
      " 10  channel_Web         196836 non-null  bool   \n",
      " 11  purchase_intensity  196836 non-null  float64\n",
      "dtypes: bool(4), float64(2), int64(6)\n",
      "memory usage: 12.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db117b1d-4201-47b0-8d7e-39d8f1366d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa71643e-97ad-4d8f-896d-bf22757f46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('purchase_intensity')['conversion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803a390-f145-4d2e-88fc-664b0e538f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2447d-eb21-4c8a-b62d-1be4b3330874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d296c50f-c325-4d3c-a3d4-71784e5ae0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052b873-1211-4a6b-bed0-fd0da02ad816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74bb18ac-14a1-4104-87e2-6ad917fb658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('conversion', axis = 1)\n",
    "y = data['conversion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b25877e1-1e4a-4fbc-9cb5-0a5024e41398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce3e103d-a2e3-4e27-9d78-57a04113bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, stratify=y, random_state=7)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d2cf692-06c4-463c-ae7c-06ada97eb1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742601671450707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 3, random_state= 7)\n",
    "dtc.fit(X_train, y_train)\n",
    "pred = dtc.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f959a-0675-4e09-a14f-91a12027f211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34bb3a4c-22fe-418a-93c3-9d456fc41895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.8602890746056342\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92     32820\n",
      "           1       1.00      0.16      0.28      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.93      0.58      0.60     39367\n",
      "weighted avg       0.88      0.86      0.82     39367\n",
      "\n",
      "2 0.8742601671450707\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "3 0.8742601671450707\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "4 0.8742601671450707\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "5 0.8742601671450707\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "6 0.8742601671450707\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "7 0.8743109711179414\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "8 0.8742855691315061\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "9 0.8737775294027993\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.98      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "10 0.8743363731043767\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.99      0.25      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "11 0.8740823532400234\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.98      0.25      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "12 0.8737267254299286\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.96      0.25      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.91      0.62      0.66     39367\n",
      "weighted avg       0.88      0.87      0.84     39367\n",
      "\n",
      "13 0.8733202936469632\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.93      0.26      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.90      0.63      0.67     39367\n",
      "weighted avg       0.88      0.87      0.84     39367\n",
      "\n",
      "14 0.872558234053903\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     32820\n",
      "           1       0.90      0.26      0.41      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.88      0.63      0.67     39367\n",
      "weighted avg       0.88      0.87      0.84     39367\n",
      "\n",
      "15 0.8715421545964894\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     32820\n",
      "           1       0.86      0.27      0.41      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.87      0.63      0.67     39367\n",
      "weighted avg       0.87      0.87      0.84     39367\n",
      "\n",
      "16 0.8710087128813473\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     32820\n",
      "           1       0.83      0.28      0.42      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.85      0.64      0.67     39367\n",
      "weighted avg       0.87      0.87      0.84     39367\n",
      "\n",
      "17 0.8698910254781924\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     32820\n",
      "           1       0.80      0.29      0.43      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.84      0.64      0.68     39367\n",
      "weighted avg       0.86      0.87      0.84     39367\n",
      "\n",
      "18 0.8679604745091066\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     32820\n",
      "           1       0.75      0.31      0.43      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.82      0.64      0.68     39367\n",
      "weighted avg       0.86      0.87      0.84     39367\n",
      "\n",
      "19 0.8658775116214088\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92     32820\n",
      "           1       0.72      0.32      0.44      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.80      0.65      0.68     39367\n",
      "weighted avg       0.85      0.87      0.84     39367\n",
      "\n",
      "20 0.8633627149643102\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     32820\n",
      "           1       0.69      0.33      0.45      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.78      0.65      0.68     39367\n",
      "weighted avg       0.85      0.86      0.84     39367\n",
      "\n",
      "21 0.8601620646734575\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.65      0.34      0.45      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.77      0.65      0.68     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "22 0.8582315137043717\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.35      0.45      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.76      0.66      0.69     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "23 0.8547768435491655\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     32820\n",
      "           1       0.60      0.37      0.46      6547\n",
      "\n",
      "    accuracy                           0.85     39367\n",
      "   macro avg       0.74      0.66      0.69     39367\n",
      "weighted avg       0.84      0.85      0.84     39367\n",
      "\n",
      "24 0.8520588310005842\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     32820\n",
      "           1       0.58      0.38      0.46      6547\n",
      "\n",
      "    accuracy                           0.85     39367\n",
      "   macro avg       0.73      0.66      0.69     39367\n",
      "weighted avg       0.83      0.85      0.84     39367\n",
      "\n",
      "25 0.8498996621535804\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     32820\n",
      "           1       0.57      0.39      0.46      6547\n",
      "\n",
      "    accuracy                           0.85     39367\n",
      "   macro avg       0.73      0.67      0.69     39367\n",
      "weighted avg       0.83      0.85      0.84     39367\n",
      "\n",
      "26 0.8483501409810247\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     32820\n",
      "           1       0.56      0.40      0.47      6547\n",
      "\n",
      "    accuracy                           0.85     39367\n",
      "   macro avg       0.72      0.67      0.69     39367\n",
      "weighted avg       0.83      0.85      0.84     39367\n",
      "\n",
      "27 0.8458099423374907\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     32820\n",
      "           1       0.55      0.41      0.47      6547\n",
      "\n",
      "    accuracy                           0.85     39367\n",
      "   macro avg       0.72      0.67      0.69     39367\n",
      "weighted avg       0.83      0.85      0.84     39367\n",
      "\n",
      "28 0.8446414509614651\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     32820\n",
      "           1       0.54      0.42      0.47      6547\n",
      "\n",
      "    accuracy                           0.84     39367\n",
      "   macro avg       0.72      0.67      0.69     39367\n",
      "weighted avg       0.83      0.84      0.84     39367\n",
      "\n",
      "29 0.8428379099245561\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     32820\n",
      "           1       0.53      0.43      0.48      6547\n",
      "\n",
      "    accuracy                           0.84     39367\n",
      "   macro avg       0.71      0.68      0.69     39367\n",
      "weighted avg       0.83      0.84      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 30):\n",
    "    dtc = DecisionTreeClassifier(max_depth = i, random_state= 7)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    pred = dtc.predict(X_valid)\n",
    "    print(i, accuracy_score(y_valid, pred))\n",
    "    print(i, classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59863ee3-3fb8-4980-9fc1-96a7244ef8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742601671450707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 6, random_state= 7)\n",
    "dtc.fit(X_train, y_train)\n",
    "pred = dtc.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81832efe-a990-4524-a9be-cacaa3cbb310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8761938630359682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.26      0.41      6548\n",
      "\n",
      "    accuracy                           0.88     39368\n",
      "   macro avg       0.94      0.63      0.67     39368\n",
      "weighted avg       0.89      0.88      0.84     39368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = dtc.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d3fb8-baa4-491f-80b1-da3b49b63ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51acaa-2f7d-454e-b0d8-bb67dc1d0cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b0f73-32dd-4e21-a80d-1f7690cd2eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc43d19c-c0e5-4cad-89dc-33b23befd45e",
   "metadata": {},
   "source": [
    "# 배깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54bd0e25-fd90-4fc7-9127-0b4bf72734a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18aefd8d-7483-4682-b74c-1b6ccb7d0310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8663093453908096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92     32820\n",
      "           1       0.74      0.30      0.43      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.81      0.64      0.68     39367\n",
      "weighted avg       0.85      0.87      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bcf = BaggingClassifier(n_estimators=10, n_jobs= -1, random_state=777)\n",
    "bcf.fit(X_train, y_train)\n",
    "pred = bcf.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c357a5f2-8d6e-4a09-b8ff-d53e99f8a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = DecisionTreeClassifier(max_depth = 6, random_state= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bdd19651-3f1f-4647-b826-a01e92363af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742601671450707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bcf = BaggingClassifier(estimator=est, n_estimators=10, n_jobs=-1, random_state=777)\n",
    "bcf.fit(X_train, y_train)\n",
    "pred = bcf.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbc98e-55f2-4dd4-b1ff-7033a979ff21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3871a-d756-4b3a-9848-9b79fad4d3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9db0b45b-a86a-4ece-9213-eea1919f9e85",
   "metadata": {},
   "source": [
    "# 부스팅 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02c94bc8-9f78-41b7-a272-9c2fb49619d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e009be6c-2a01-4e55-8f1a-e06d730d9898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742347651586354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=1000, max_depth=3, learning_rate = 0.1, n_jobs= -1, random_state = 777 )\n",
    "xgb.fit(X_train, y_train)\n",
    "pred = xgb.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94973b1d-2264-4f7a-9b42-dc0773ebbd3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742601671450707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "0.8742601671450707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "0.8742347651586354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "0.8740315492671527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.99      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "0.8734727055655752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "0.872786851931821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.94      0.25      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.91      0.62      0.66     39367\n",
      "weighted avg       0.88      0.87      0.84     39367\n",
      "\n",
      "0.8711103208270887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     32820\n",
      "           1       0.90      0.25      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.88      0.62      0.66     39367\n",
      "weighted avg       0.87      0.87      0.84     39367\n",
      "\n",
      "0.8701196433561105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     32820\n",
      "           1       0.85      0.27      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.86      0.63      0.67     39367\n",
      "weighted avg       0.87      0.87      0.84     39367\n",
      "\n",
      "0.8657759036756675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92     32820\n",
      "           1       0.77      0.27      0.41      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.82      0.63      0.66     39367\n",
      "weighted avg       0.85      0.87      0.84     39367\n",
      "\n",
      "0.8638199507201463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92     32820\n",
      "           1       0.73      0.28      0.41      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.80      0.63      0.67     39367\n",
      "weighted avg       0.85      0.86      0.84     39367\n",
      "\n",
      "0.861330556049483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     32820\n",
      "           1       0.70      0.29      0.41      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.79      0.63      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8607971143343409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     32820\n",
      "           1       0.68      0.30      0.42      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.78      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8605176924835523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     32820\n",
      "           1       0.68      0.31      0.42      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.78      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.859450809053268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     32820\n",
      "           1       0.67      0.31      0.42      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.77      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8591459852160439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     32820\n",
      "           1       0.66      0.31      0.42      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.77      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8580028958264536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     32820\n",
      "           1       0.65      0.31      0.42      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.76      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8581299057586304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     32820\n",
      "           1       0.65      0.32      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.76      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8578504839078416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     32820\n",
      "           1       0.65      0.32      0.42      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.76      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8575710620570529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     32820\n",
      "           1       0.65      0.32      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.76      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8568852084232987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.64      0.32      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.76      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8560977468438031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.32      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.75      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8561739528031092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.32      0.42      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.76      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8554880991693551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.32      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.75      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8561231488302385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.33      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.75      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8563771686945919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.33      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.75      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8555135011557904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.33      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.75      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8556151091015317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.33      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.75      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n",
      "0.8548530495084715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.62      0.33      0.43      6547\n",
      "\n",
      "    accuracy                           0.85     39367\n",
      "   macro avg       0.75      0.64      0.67     39367\n",
      "weighted avg       0.83      0.85      0.84     39367\n",
      "\n",
      "0.8553610892371784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     32820\n",
      "           1       0.63      0.33      0.43      6547\n",
      "\n",
      "    accuracy                           0.86     39367\n",
      "   macro avg       0.75      0.64      0.67     39367\n",
      "weighted avg       0.84      0.86      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,30):\n",
    "    xgb = XGBClassifier(n_estimators=1000, max_depth=i, learning_rate = 0.1, n_jobs= -1, random_state = 777 )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    pred = xgb.predict(X_valid)\n",
    "    print(accuracy_score(y_valid, pred))\n",
    "    print(classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fce19d-ee11-4286-96c0-9f7eeab50d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "43b1a370-d7e4-4452-b6e3-b6c78a9a5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77aea721-0142-49ca-a515-52a762d6378c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19643, number of negative: 98458\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 118101, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166324 -> initscore=-1.611909\n",
      "[LightGBM] [Info] Start training from score -1.611909\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.8742601671450707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=1000, max_depth=3, learning_rate = 0.1, n_jobs= -1, random_state = 777 )\n",
    "lgbm.fit(X_train, y_train)\n",
    "pred = lgbm.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be9bc198-bd43-41c8-a8af-8ebc2781f5a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.8742601671450707\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "2 0.8742601671450707\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "3 0.8742601671450707\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "4 0.8740315492671527\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.99      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "5 0.8735235095384459\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "6 0.8734727055655752\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "7 0.8734219015927045\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "8 0.8735489115248812\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "9 0.8733964996062692\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "10 0.8740061472807173\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.98      0.25      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "11 0.8735489115248812\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "12 0.8734473035791399\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "13 0.8734981075520105\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "14 0.8734981075520105\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "15 0.8736251174841873\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "16 0.873675921457058\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.40      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "17 0.8734219015927045\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "18 0.8733456956333985\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "19 0.8734219015927045\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "20 0.8734473035791399\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "21 0.8735743135113165\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "22 0.8735235095384459\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "23 0.8736251174841873\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "24 0.8736251174841873\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "25 0.8736251174841873\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "26 0.8736251174841873\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "27 0.8736251174841873\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "28 0.8736251174841873\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "29 0.8736251174841873\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       0.97      0.25      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.92      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,30):\n",
    "    lgbm = LGBMClassifier(n_estimators=1000, max_depth=i, learning_rate = 0.1, n_jobs= -1, random_state = 777, verbose=-1 )\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    pred = lgbm.predict(X_valid)\n",
    "    print(i, accuracy_score(y_valid, pred))\n",
    "    print(i, classification_report(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869e38e-c593-45f3-9146-abd875e1937b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e2116-2102-4de0-9f07-b4bf2b0aff54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdaf4dcd-aa78-4325-be38-a1c6264ded57",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e008b907-85fa-4aa1-919f-7d7e689b79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d83b650-5e9e-40a7-9dde-827538759f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = dict(n_estimators=[100,500,1000,1500], max_depth=[1,3,5,7], learning_rate = [0.1,0.5,1.0], n_jobs= [-1], random_state = [777], sampling_method = [ 'uniform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4bf0e622-2559-4110-ae67-1cfb0fd250e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f80e595-3310-4844-bae5-32d76d412ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "['mean_fit_time', 'mean_score_time', 'mean_test_score', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_n_jobs', 'param_random_state', 'param_sampling_method', 'params', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "최적 하이퍼파라미터 : {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 777, 'sampling_method': 'uniform'}\n",
      "최고 예측 정확도 : 0.8750\n"
     ]
    }
   ],
   "source": [
    "grid_cv = GridSearchCV(xgb, param_grid = xgb_params, cv =5, n_jobs=-1, verbose=3)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "pred = grid_cv.predict(X_valid)\n",
    "print(sorted(grid_cv.cv_results_.keys()))\n",
    "print(\"최적 하이퍼파라미터 :\", grid_cv.best_params_)\n",
    "print(f\"최고 예측 정확도 : {grid_cv.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeeb7b9-7675-4320-a28d-dea3cc747e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d3b47e24-08a5-4c0d-ba18-2a68badcd1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742347651586354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.24      0.39      6547\n",
      "\n",
      "    accuracy                           0.87     39367\n",
      "   macro avg       0.93      0.62      0.66     39367\n",
      "weighted avg       0.89      0.87      0.84     39367\n",
      "\n",
      "==================== test 결과 ====================\n",
      "0.8761938630359682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     32820\n",
      "           1       1.00      0.26      0.41      6548\n",
      "\n",
      "    accuracy                           0.88     39368\n",
      "   macro avg       0.94      0.63      0.67     39368\n",
      "weighted avg       0.89      0.88      0.84     39368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(n_estimators=1000, max_depth=3, learning_rate = 0.1, n_jobs= -1, random_state = 777 )\n",
    "xgb3.fit(X_train, y_train)\n",
    "pred3 = xgb3.predict(X_valid)\n",
    "print(accuracy_score(y_valid, pred3))\n",
    "print(classification_report(y_valid, pred3))\n",
    "print(\"=\"*20, 'test 결과', \"=\"*20)\n",
    "pred3_test = xgb3.predict(X_test)\n",
    "print(accuracy_score(y_test, pred3_test))\n",
    "print(classification_report(y_test, pred3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81eb4d-0312-4643-94fd-2e59746bf921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "319821bc-bf2d-4eaf-86ab-e507a4015edc",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ffb0d71b-333c-4bc9-bad6-af0c0c4527d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5-04\\miniforge3\\envs\\fintech\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 48 is smaller than n_iter=100. Running 48 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_fit_time', 'mean_score_time', 'mean_test_score', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_n_jobs', 'param_random_state', 'param_sampling_method', 'params', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "최적 하이퍼파라미터 : {'sampling_method': 'uniform', 'random_state': 777, 'n_jobs': -1, 'n_estimators': 100, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "최고 예측 정확도 : 0.8750\n"
     ]
    }
   ],
   "source": [
    "rand_cv = RandomizedSearchCV(xgb, param_distributions = xgb_params, n_iter=100, cv =5, n_jobs=-1, verbose=3, random_state=77)\n",
    "rand_cv.fit(X_train, y_train)\n",
    "pred = rand_cv.predict(X_valid)\n",
    "print(sorted(rand_cv.cv_results_.keys()))\n",
    "print(\"최적 하이퍼파라미터 :\", rand_cv.best_params_)\n",
    "print(f\"최고 예측 정확도 : {rand_cv.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba0786-9794-482e-a025-738490a8357d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99951e5b-3723-42d0-82aa-1d56d82b7450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39a33c66-577a-45b5-8ac2-0a1e31269518",
   "metadata": {},
   "source": [
    "# lightgbm에 gridcv, randomizedcv 사용해 최적 파라미터 탐색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93f9f57c-033c-45f7-85a9-b3d9c95eeb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params2 = dict(n_estimators=[100,500,1000,1500], max_depth=[1,3,5,7], learning_rate = [0.1,0.5,1.0], n_jobs= [-1], random_state = [777], sampling_method = [ 'uniform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c10e5a4-8992-436a-95d1-d1b7bf085c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm2 = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5816fc65-965f-49ae-828b-d1ac5b6bdc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "['mean_fit_time', 'mean_score_time', 'mean_test_score', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_n_jobs', 'param_random_state', 'param_sampling_method', 'params', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "최적 하이퍼파라미터 : {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 777, 'sampling_method': 'uniform'}\n",
      "최고 예측 정확도 : 0.8750\n"
     ]
    }
   ],
   "source": [
    "grid_cv = GridSearchCV(xgb, param_grid = xgb_params, cv =5, n_jobs=-1, verbose=3)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "pred = grid_cv.predict(X_valid)\n",
    "print(sorted(grid_cv.cv_results_.keys()))\n",
    "print(\"최적 하이퍼파라미터 :\", grid_cv.best_params_)\n",
    "print(f\"최고 예측 정확도 : {grid_cv.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17aa404-c059-49fc-a00c-00e750fdeff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4c7ab7ae-77dd-4209-af49-3adc75129bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5-04\\miniforge3\\envs\\fintech\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 48 is smaller than n_iter=100. Running 48 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_fit_time', 'mean_score_time', 'mean_test_score', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_n_jobs', 'param_random_state', 'param_sampling_method', 'params', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "최적 하이퍼파라미터 : {'sampling_method': 'uniform', 'random_state': 777, 'n_jobs': -1, 'n_estimators': 100, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "최고 예측 정확도 : 0.8750\n"
     ]
    }
   ],
   "source": [
    "rand_cv = RandomizedSearchCV(estimator=lgbm2, param_distributions=lgbm_params2, n_iter=100, cv=5, n_jobs=-1, verbose=3, random_state=77)\n",
    "rand_cv.fit(X_train, y_train)\n",
    "pred = rand_cv.predict(X_valid)\n",
    "print(sorted(rand_cv.cv_results_.keys()))\n",
    "print(\"최적 하이퍼파라미터 :\", rand_cv.best_params_)\n",
    "print(f\"최고 예측 정확도 : {rand_cv.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759905b-f76b-4de3-9190-eb2b80e52d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531e10f-e008-4b5d-b012-31593a47665b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04b5a2a0-6fe9-4397-8dab-a8a67cc4d657",
   "metadata": {},
   "source": [
    "# RandomForest에 gridcv, randomizedcv 사용해 최적 파라미터 탐색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "16476ebf-8edb-4ce9-b06a-8d23c7248443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a6dd0ca5-d87f-423f-a14d-0b22d92ee4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = dict(n_estimators=[100,500,1000,1500], max_depth=[1,3,5,7, 9], n_jobs= [-1], random_state = [7, 77, 777], criterion = ['gini', 'entropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09859b25-d4ec-4f39-b61e-ec110c93fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "939ad316-f795-40b2-a0a8-0436d0af86c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "['mean_fit_time', 'mean_score_time', 'mean_test_score', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_n_jobs', 'param_random_state', 'param_sampling_method', 'params', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "최적 하이퍼파라미터 : {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 777, 'sampling_method': 'uniform'}\n",
      "최고 예측 정확도 : 0.8750\n"
     ]
    }
   ],
   "source": [
    "grid_cv = GridSearchCV(xgb, param_grid = xgb_params, cv =5, n_jobs=-1, verbose=3)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "pred = grid_cv.predict(X_valid)\n",
    "print(sorted(grid_cv.cv_results_.keys()))\n",
    "print(\"최적 하이퍼파라미터 :\", grid_cv.best_params_)\n",
    "print(f\"최고 예측 정확도 : {grid_cv.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713fa3c-8ce6-4f8b-baa2-3710b400a50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8fd06-32e0-4813-97ba-9d0c6d43a979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "rand_cv = RandomizedSearchCV(rfc, param_distributions=rfc_params, n_iter=100, cv=5, n_jobs=-1, verbose=3, random_state=77)\n",
    "rand_cv.fit(X_train, y_train)\n",
    "pred = rand_cv.predict(X_valid)\n",
    "print(sorted(rand_cv.cv_results_.keys()))\n",
    "print(\"최적 하이퍼파라미터 :\", rand_cv.best_params_)\n",
    "print(f\"최고 예측 정확도 : {rand_cv.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f76d4-0d91-4dcd-9881-c0756e7ea61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4f1d3-fe4b-4df5-8a0f-e46850643c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c9db47-caf2-4e2f-a41f-37ba3ed2d743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
